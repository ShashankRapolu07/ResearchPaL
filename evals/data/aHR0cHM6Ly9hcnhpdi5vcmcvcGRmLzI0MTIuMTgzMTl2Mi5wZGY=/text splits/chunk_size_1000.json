[
    "Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via\nCollective Monte Carlo Tree Search\nHuanjin Yao2,3,\u2217Jiaxing Huang1,\u2217,\f Wenhao Wu3 Jingyi Zhang1 Yibo Wang2 Shunyu Liu1 Yingjie Wang1\nYuxin Song3 Haocheng Feng3 Li Shen4 Dacheng Tao1\nAbstract\nIn this work, we aim to develop an MLLM that\nunderstands and solves questions by learning\nto create each intermediate step of the reason-\ning involved till the final answer. To this end,\nwe propose Collective Monte Carlo Tree Search\n(CoMCTS), a new learning-to-reason method for\nMLLMs, which introduces the concept of col-\nlective learning into \u201ctree search\u201d for effective\nand efficient reasoning-path searching and learn-\ning. The core idea of CoMCTS is to leverage\ncollective knowledge from multiple models to\ncollaboratively conjecture, search and identify ef-\nfective reasoning paths toward correct answers\nvia four iterative operations including Expansion,\nSimulation and Error Positioning, Backpropaga-\ntion, and Selection. Using CoMCTS, we con-\nstruct Mulberry-260k, a multimodal dataset with\na tree of rich, explicit and well-defined reason-\ning nodes for each question.\nWith Mulberry-\n260k, we perform collective SFT to train our\nmodel, Mulberry, a series of MLLMs with o1-\nlike step-by-step Reasoning and Reflection capa-\nbilities. Extensive experiments demonstrate the\nsuperiority of our proposed methods on various\nbenchmarks. Code will be available at https:\n//github.com/HJYao00/Mulberry\n1. Introduction\n\u201cWhat I cannot create, I do not understand.\u201d\n\u2014Richard Feynman\nMultimodal large language models (MLLMs) embody the\nessence of this dictum, which understand the world by learn-\ning to create expected responses to multimodal inputs such\nas images and text. While MLLMs have recently shown sig-\n\u2217Equal Contribution. Correspondence to: Jiaxing Huang <ji-\naxing.huang@ntu.edu.sg>. 1 Nanyang Technological University;\n2 Tsinghua University; 3 Baidu Inc.; 4 Sun Yat-sen University.\nAverage Search Iteration (times)\n10\n20\n30\n40\n50\n60\nSearch Success Rate (%)\n50\n60\n70\n80\n90\n100\nGPT4o (direct pred)\nMCTS\nOmega-MCTS\nIter-MCTS\nCoMCTS\nSearch Success Rate\nAverage Search Iteration\n12.7\n24.3\n36.3\n42.1\n80.2\n66.2\n65.6\n63.8\n58.2\nAccuracy (%)\n30\n38\n46\n54\n62\n70\n3.5\n7\n10.5\n14\nN/A\n2B\n7B\n8B\n11B\nMulberry-2B\nMulberry-7B\nMulberry-LLaVA-8B\nMulberry-LLaMA-11B\nQwen2-VL\u20132B\nQwen2-VL\u20137B\nMiniCPM-V\u20132 (2.8B)\nLLaVA-NeXT-8B\nLLaVA-NeXT-7B\nLLaVA-Reasoner 8B\nLLaMA3.2-VL-11B\nLLaVA-COT\nGPT-4o\nGemini 1.5 Flash\nModel Size\n(a) Comparison of Search Success Rates and Average Search Iterations\n(b) Accuracy on MathVista\nOur models\nBaseline models\n+8.7\n+4.9\nMM1-7B-MoE\n+18.8\n+12.5\nFigure 1: (a) Our CoMCTS shows great superiority in\nsearch effectiveness and efficiency against other tree search\nmethods. (b) Our Mulberry, trained on CoMCTS-searched\ndata, outperforms most open-sourced MLLMs and achieves\ncompetitive results against closed-source ones, showing out-\nstanding abilities in step-by-step reasoning and reflection.\nnificant progress in straightforward tasks (Liu et al., 2024;",
    "competitive results against closed-source ones, showing out-\nstanding abilities in step-by-step reasoning and reflection.\nnificant progress in straightforward tasks (Liu et al., 2024;\nWang et al., 2024b), they often experience obviously in-\ncreased failures on complex tasks requiring in-depth rea-\nsoning (Zhang et al., 2024d). Feynman\u2019s dictum might be\nthe perfect metaphor of such failures of MLLMs, as we\nshould only be able to work something out if we can create\nand have a firm understanding of each step of the reasoning\ninvolved. However, current MLLMs predominantly oper-\nate in a simple \u201cdirect prediction\u201d mode (Xu et al., 2024),\ni.e., generating brief, final answers to questions with little\nexplicit and well-defined intermediate reasoning steps.\nIn this work, we aim to develop an MLLM that understands\nand solves questions by learning to create each intermediate\nstep of the reasoning involved till the final answer. Recent\nadvances in NLP, such as OpenAI o1 (OpenAI, 2024), have\n1\narXiv:2412.18319v2  [cs.CV]  31 Dec 2024\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nshown great potential in enabling LLM to learn to reason and\ntackle complex language tasks (Xie et al., 2024). The core\ndesign of these advances lies in AlphaGo-like \u201ctree search\u201d:\nthey employ tree search methods, like MCTS (Coulom,\n2006), to bootstrap an LLM itself to build a tree of inter-\nmediate thoughts, explore effective reasoning paths, and\nleverage these paths to teach the model to reason step-by-\nstep.\nAn intuitive idea is to directly apply these \u201ctree search\u201d meth-\nods to search effective reasoning paths for MLLMs, which,\nhowever, does not work well. As illustrated in Figure 1, we\nbelieve this is largely attributed to several observed search\nchallenges for MLLMs. (1) Search Effectiveness: Tradi-\ntional MCTS methods generally work by self-bootstrapping\nwhile current MLLMs are typically trained with little ex-\nplicit and well-defined intermediate reasoning steps, making\nthese search methods often trapped in homogeneous low-\nquality nodes within the reasoning space of a single MLLM,\nultimately leading to low search success rates. (2) Search\nEfficiency: Traditional MCTS methods typically expand\nand explore only one subsequent reasoning node per search\niteration, which advance a single step each time and demand\nmassive iterations, making them inefficient for computation-\nintensive MLLMs.\nTo tackle these challenges, we propose Collective Monte\nCarlo Tree Search (CoMCTS), a new learning-to-reason\nmethod for MLLMs, which introduces the concept of col-\nlective learning into \u201ctree search\u201d for effective and efficient\nreasoning-path searching and learning. The core idea of\nCoMCTS is to leverage collective knowledge to collabo-\nratively conjecture, search and identify effective reason-\ning paths toward correct answers. Specifically, CoMCTS\nsearches effective reasoning paths iteratively, and in each\niteration, it leverages collective knowledge from multiple\nMLLMs to jointly (a) expand diverse and complementary\ncandidate subsequent reasoning nodes till the end from a\ngiven start node, (b) simulate reasoning outcomes, posi-\ntion error candidate nodes and prune them along with their\nchild nodes, (c) backpropagate to update the score and visit\ncount of each reasoning node in a bottom-up manner, and\n(d) select the leaf reasoning node with the highest Upper\nConfidence Bound value as next start node.\nIn this way, our CoMCTS achieves effective and efficient\nreasoning search. (1) The joint expansion mechanism en-\nables CoMCTS to concatenate reasoning trajectories from\nmultiple MLLMs via iterative search, ultimately construct-\ning an unified reasoning tree comprising diverse and com-\nplementary reasoning nodes. Thus, it allows reasoning-path\nsearch not only within the reasoning space of a given MLLM\nitself but also among those of others, benefiting from the\nsynergy of multiple MLLMs while avoiding being trapped\nin homogeneous low-quality nodes within the reasoning\nspace of a single MLLM itself. (2) The joint simulation and",
    "synergy of multiple MLLMs while avoiding being trapped\nin homogeneous low-quality nodes within the reasoning\nspace of a single MLLM itself. (2) The joint simulation and\nerror positioning mechanism enables CoMCTS to, in each\nsearch iteration, skip multiple intermediate steps and select\nthe last correct step as the next start node, largely reducing\nsearch time while maintaining search effectiveness. Here,\ncollective knowledge is also crucial as it is often challenging\nfor a model to recognize and position errors made by itself\nwhile relatively easy by using other models.\nFurthermore, we extend our CoMCTS for reflective\nreasoning-path search. Based on the unified reasoning tree\nconstructed by CoMCTS, which provides both positive and\nnegative reasoning nodes , we identify and integrate nega-\ntive sibling nodes into effective reasoning paths to build the\nreflective reasoning path that includes a transition from a\nnegative reasoning node to a positive one. By learning from\nreflective reasoning paths, MLLMs can perform appropriate\nstep-wise reflection, dynamically calibrating their reason-\ning trajectory from an erroneous node toward a correct one\nduring long-chain reasoning. Here, collective knowledge\nfacilitates reflective reasoning-path search by providing a\nrich set of diverse positive and negative reasoning nodes.\nUsing our CoMCTS, we search effective and reflective\nreasoning paths for a set of multimodal inputs, and con-\nstruct Mulberry-260k, a Multimodal learning-to-Reason-\nand-Reflect dataset with a tree of rich, explicit and well-\ndefined reasoning nodes for each question. With Mulberry-\n260k, we perform collective supervised fine-tuning to train\nour model, Mulberry, a series of Multimodal LLMs with\no1-like step-by-step Reasoning and Reflection capabilities.\nThe main contributions of this work are fourfold. First, we\nintroduce the concept of collective learning into MCTS, and\npropose CoMCTS which leverages collective knowledge\nto collaboratively conjecture, search and identify effective\nand reflective reasoning paths for MLLMs, showing great\nsuperiority in search effectiveness and efficiency. To the\nbest of our knowledge, this is the first work that explores\ncollective learning with MCTS for MLLMs. Second, we\nconstruct Mulberry-260k that provides a valuable resource\nfor advancing research in step-by-step reasoning and re-\nflection in MLLMs. Third, we develop Mulberry, a series\nof MLLMs with outstanding capabilities in step-by-step\nreasoning and reflection. Fourth, extensive experiments\ndemonstrate the superiority of our proposed methods on\nvarious benchmarks.\n2. Related Works\n2.1. Multimodal Large Language Model\nMLLMs (Liu et al., 2024; Wang et al., 2024b; Lu et al.,\n2024a; Yao et al., 2024a) have made notable advancements\nin general vision-language understanding, enabling them\nto interpret visual semantics across various domains. Re-\n2\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\ncent studies (Yue et al., 2024; Zhang et al., 2024d) explore\nMLLM reasoning and reveal that directly employing CoT\nprompt to derive the final answer may result in limited\ngains or even degradation. In addition, some studies (Mitra\net al., 2024; Luan et al., 2024) introduce plan-based CoT\nprompting to guide models to generate intermediate infor-\nmation for predicting final answers. Recent advances (Xu\net al., 2024) attempt structured reasoning with a planed flow\nof certain pre-defined stages, enhancing the CoT capabili-\nties (Zhang et al., 2024c) of MLLMs. Differently, this paper,\nfor the first time, introduces the concept of \u201ctree search\u201d into\nMLLM reasoning and proposes a novel CoMCTS technique\nto search effective and reflective reasoning paths to train our\nMulberry, a series of MLLMs with outstanding capabilities\nin step-by-step reasoning and reflection.\n2.2. Large Language Model Reasoning\nLLM reasoning methods can be broadly categorized\ninto three types, including prompt-based, plan-based and\nlearning-based reasoning.\nPrompt-based methods, like\nChain-of-Thought (CoT) (Wei et al., 2022), mimic hu-\nman reasoning by providing a few hand-crafted, step-by-",
    "Prompt-based methods, like\nChain-of-Thought (CoT) (Wei et al., 2022), mimic hu-\nman reasoning by providing a few hand-crafted, step-by-\nstep solutions as references. Plan-based methods, such as\nTree/Graph-of-thought (Yao et al., 2024b; Besta et al., 2024),\npredict multiple reasoning paths in a tree or graph manner\nand take consistent units of thought for thoughtful decision-\nmaking. Learning-based reasoning methods, represented\nby GPTo1, Star (Zelikman et al., 2022), Iter-MCTS (Xie\net al., 2024) and ReST-MCTS (Zhang et al., 2024a), first\nemploy tree search approaches, like MCTS, to bootstrap an\nLLM itself to build a tree of intermediate thoughts, explore\neffective reasoning paths, and leverage these paths to train\nthe model to reason step-by-step.\n2.3. Monte-Carlo Tree Search\nMonte-Carlo Tree Search (MCTS) is a powerful search\nparadigm for complex decision making problems and has\nbeen extensively explored across diverse fields, including\ngames (Silver et al., 2017; Ye et al., 2021), robotics (Best\net al., 2019; Dam et al., 2022), theorem proving (Lample\net al., 2022), matrices multiplication (Fawzi et al., 2022),\netc. For instance, AlphaGo (Silver et al., 2017) introduces\ndeep learning into MCTS, achieving superhuman perfor-\nmance in board and video games (Silver et al., 2017; Ye\net al., 2021). Besides, (Pitanov et al., 2023; Yang, 2023) ex-\nplore MCTS for path finding and train timetabling problems,\nwhile (Vagadia et al., 2024) integrates MCTS into physics-\ninformed planning networks for robot control. In this work,\nwe propose CoMCTS that enables effective and reflective\nreasoning-path searching and learning on MLLMs.\n2.4. Collective Learning\nCollective learning, also known as Co-training, aims to\nharness collective intelligence of multiple individuals to im-\nprove learning outcomes. This concept originates in early\npioneering studies (Blum & Mitchell, 1998; Sun & Jin,\n2011; Yu et al., 2011), which utilize collective knowledge\nto address data insufficiency issues in classification learning.\nRecent advances introduce collective learning into deep neu-\nral networks for efficient and effective deep learning. For\nexample, (Qiao et al., 2018; Saito et al., 2018) employ col-\nlective knowledge from multiple classifiers to predict more\naccurate pseudo-labels for semi-supervised classification;\n(Cui et al., 2022) utilizes collective knowledge from mul-\ntiple discriminators to enhance image discrimination and\ngeneration; and (Foerster et al., 2016) leverages the synergy\nof multiple models for reinforcement learning.\n3. Methodology\nWe first present our proposed CoMCTS that introduces the\nconcept of collective learning into \u201ctree search\u201d for effective\nand efficient reasoning-path searching and learning. We then\nillustrate the extension of CoMCTS for reflective reasoning-\npath search, and describe data construction (i.e., Mulberry-\n260k) and model training (i.e., Mulberry) using CoMCTS.\nMore details to be elaborated in the ensuing subsections.\n3.1. CoMCTS for effective reasoning\nThe core idea of CoMCTS is to leverage collective knowl-\nedge to collaboratively conjecture, search and identify effec-\ntive reasoning nodes in an iterative manner, aiming to find\neffective reasoning paths leading to correct answers.\nWe denote a policy model as \u03c0, which is initialized by\na pre-trained MLLM. We leverage collective knowledge\nfrom a group of MLLMs {\u03c01, \u03c02, ..., \u03c0K} to jointly search\nand learn effective reasoning paths. Given a multimodal\ninput question Q (e.g., a text task instruction with an image,\nQ = {text, image}), each model \u03c0 can generate a sequence\nof intermediate reasoning states toward the final answer\n(s1, s2, s3, ..., sM) \u223c\u03c0\u03b8(\u00b7|Q) via autoregressive next token\nprediction. We define the intermediate reasoning state at\nstep m as sm and the state generated by model \u03c0k at step\nm as sk",
    "prediction. We define the intermediate reasoning state at\nstep m as sm and the state generated by model \u03c0k at step\nm as sk\nm. Each reasoning step consists of one or a few\nsentences containing multiple word tokens.\nCoMCTS algorithm begins at the root node, i.e., either the\nstart of a response or an incomplete response, and performs\nreasoning-path search via a certain number of iterations,\nwhere each iteration comprises four key operations: (a)\nExpansion, (b) Simulation and Error Positioning, (c) Back-\npropagation, and (d) Selection, as elaborated below.\n(a) Expansion. The goal of this operation in CoMCTS\n3\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nUpdated Model \ud835\udf0b!\n\u2217\nUpdated Model \ud835\udf0b#\n\u2217\nUpdated Policy Models\nReasoning Path Search with CoMCTS\nModel Training with CoMCTS\nExpansion\nRepeat X times or till found correct reasoning path\nSimulation and Error Positioning\nBackpropagation\nSelection\nSearched Reasoning Paths\nPolicy Model \ud835\udf0b$\nQuestion: Find the \nperimeter of the triangle\n\ud835\udc46!\n\ud835\udc46\"!\n\ud835\udc46!\n\ud835\udc46!\n\ud835\udc46!\nOrange, Blue and Green denote reasoning nodes \ngenerated by different policy models \ud835\udf0b$ , \ud835\udf0b# , \ud835\udf0b! \nSelected nodes\nPolicy Model \ud835\udf0b#\nUnselected nodes\nTemporary nodes\nPolicy Model \ud835\udf0b!\nUpdated Model \ud835\udf0b$\n\u2217\n(a) CoSFT\nQ\n1\n2\n3\n1\n2\n3\n2\n3\n3\nQ\n1\n2\n3\n1\n2\n3\n2\n3\n3\n1\n2\n3\n1\n2\n2\n3\n(b) CoSFT for Reflective Reasoning\n(a)\n(b)\nCoSFT with CoMCTS Data\n\ud835\udc46\"\n\"\n\ud835\udc46\"\n#\n\ud835\udc46\"\n\"\n\ud835\udc46\"\n#\n\ud835\udc46\"\n\"\n\ud835\udc46\"\n#\n\ud835\udc46\"\n\"\n\ud835\udc46\"\n#\n\ud835\udc46\"\n!\n\ud835\udc46\"\n!\n\ud835\udc46\"\n!\n\ud835\udc46#\n!\n\ud835\udc46#\n\"\n\ud835\udc46#\n#\n\ud835\udc46$\n!\n\ud835\udc46$\"\n\ud835\udc46$\n#\n\ud835\udc46%\n!\n\ud835\udc46%\n\"\n\ud835\udc46%\n#\n\ud835\udc46&\n!\n\ud835\udc46'\n\"\n\ud835\udc46'\n#\n\ud835\udc46#\n!\n\ud835\udc46#\n\"\n\ud835\udc46#\n#\n\ud835\udc46$!\n\ud835\udc46$\"\n\ud835\udc46$#\n\ud835\udc46%\n!\n\ud835\udc46%\n\"\n\ud835\udc46%\n#\n\ud835\udc46'\n!\n\ud835\udc46'\n\"\n\ud835\udc46'\n#\n\ud835\udc46#\n!\n\ud835\udc46#\n\"\n\ud835\udc46#\n#\n\ud835\udc46$!\n\ud835\udc46$\n#\n\ud835\udc46%\n#\n\ud835\udc46#\n!\n\ud835\udc46#\n\"\n\ud835\udc46#\n#\n\ud835\udc46$!\n\ud835\udc46$\n#\n\ud835\udc46%\n#\nFigure 2: Overview. Our CoMCTS trains Mulberry with two alternating phases. In top part, CoMCTS searches reasoning\npaths iteratively, and in each iteration, it utilizes collective knowledge from multiple MLLMs to jointly (a) expand diverse\nand complementary candidate subsequent reasoning nodes till the end from a given start node, (b) simulate reasoning\noutcomes, position error candidate nodes and prune them along with their child nodes, (c) backpropagate to update the score\nand visit count of each reasoning node in a bottom-up manner, and (d) select the leaf reasoning node with the highest UCB\nvalue as next start node. In bottom part, we train the model to learn from the reasoning trees constructed by CoMCTS.\nis to expand the current leaf reasoning node (if it is not a\nterminal node) to integrate new subsequent candidate rea-\nsoning nodes. Given the current leaf node sk",
    "is to expand the current leaf reasoning node (if it is not a\nterminal node) to integrate new subsequent candidate rea-\nsoning nodes. Given the current leaf node sk\nm (i.e., the\nnode selected by Operation (d) Selection or the root node),\nCoMCTS utilizes collective knowledge from a group of\nMLLMs, {\u03c01, \u03c02, ..., \u03c0K}, to jointly expand a set of diverse\nand complementary candidate reasoning paths Scandidate =\n\u222aK\nj=1Sj\ncandidate in parallel till the terminal node:\nSj\ncandidate \u223c\u03c0j(\u00b7|Q, Parent(sk\nm), sk\nm),\n(1)\nwhere Parent(sk\nm) returns all parent nodes of sk\nm and\n(Parent(sk\nm), sk\nm) denotes the current reasoning path from\nthe root node to sk\nm. Sj\ncandidate = {sj\ni} stands for a potential\nreasoning path generated by model \u03c0j starting from sk\nm.\n(b) Simulation and Error Positioning.\nIn this op-\neration, CoMCTS utilizes collective knowledge from\n{\u03c01, \u03c02, ..., \u03c0K} to jointly estimate the potential value of\nchild nodes sj\ni \u2208Scandidate (added in Operation (a)), and con-\nsiders low-score nodes as erroneous reasoning nodes, and\npositions and filters out them along with their child nodes:\nR(sj\ni) = 1\nK\nK\nX\nl=1\n\u03c0l(\u00b7|prompteval, Q, Parent(sj\ni), sj\ni)\n(2)\nS\u2217\ncandidate = {sj\ni \u2208Scandidate|R(sj\ni) >= t}\n(3)\nwhere R(sj\ni) denotes a reasoning node evaluation func-\ntion that uses the prompt, prompteval, to request a group\nof MLLMs, {\u03c01, \u03c02, ..., \u03c0K}, to jointly evaluate the candi-\ndate reasoning node sj\ni. t is a threshold and Discontinued\nreasoning nodes in S\u2217\ncandidate are automatically removed fol-\nlowing the error node removal in Eq.(3).\n(c) Backpropagation. Given the new reasoning tree ex-\npanded and simulated using collective knowledge in Opera-\ntions (a)-(b), CoMCTS performs a bottom-up update from\nthe leaf nodes back to the root node. Each node s along\nthe newly expanded path in the reasoning tree updates its\nstatistics, including visit count N and node value V :\nV (s) \u2190\u2212\nN(s) \u00b7 V (s) + P\nsl\u2208Child(s) R(sl)\nN(s) + CountChild(S\u2217\ncandidate, s) ,\n(4)\nN(s) \u2190\u2212N(s) + CountChild(S\u2217\ncandidate, s),\n(5)\nwhere Child(s) returns all the child nodes of s, and\nCountChild(S\u2217\ncandidate, s) is a child node counting function\nthat calculates the number of child nodes of s in S\u2217\ncandidate.\n(d) Selection. Following Operations (a), (b) and (c), CoM-\nCTS traverses the updated reasoning tree to select the next\n4\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nstarting node. This selection is guided by the Upper Con-\nfidence Bound (UCB) value, which balances search explo-\nration and exploitation. The UCB value of a node s is\ncomputed using the node reward value V (s) and the visit\ncound N(s). Among the candidate nodes s \u2208S\u2217\ncandidate, the\none with the highest UCB value is chosen as the starting\nnode sk\u2217\nm for next search iteration:\nsk\u2217\nm = arg max\ns\u2208S\u2217\ncandidate\nV (s) + c \u00b7\ns\nlog N(\u02c6s)\n1 + N(s)\n(6)\nwhere c stands for a constant which controls the level of\nexploration. \u02c6s denotes the parent node of s.\nCoMCTS. These four operations, i.e., (a) Expansion, (b)",
    "where c stands for a constant which controls the level of\nexploration. \u02c6s denotes the parent node of s.\nCoMCTS. These four operations, i.e., (a) Expansion, (b)\nSimulation and Error Positioning, (c) Backpropagation and\n(d) Selection, are repeated for a pre-defined number of it-\nerations or until correct reasoning paths are found. This\niterative process allows CoMCTS to construct a question-\ndependent reasoning tree S with the correct reasoning path\nY , and ultimately form a multimodal learning-to-reason\ndata triplet {Q, Y, S}. By applying our CoMCTS to a set\nof multimodal questions, we can construct a collection of\nmultimodal learning-to-reason data triplets, which provide\na tree of rich, explicit and well-defined reasoning nodes to-\nward the final answer for each question and enable MLLMs\nto learn to reason step-by-step.\n3.2. CoMCTS for reflective reasoning\nIn this subsection, we extend CoMCTS for reflective\nreasoning-path search. Based on the unified reasoning tree\nconstructed by CoMCTS, i.e., {Q, Y, S}, which provides\nboth positive and negative reasoning nodes, we identify\nand integrate negative sibling nodes into effective reasoning\npaths to build the reflective reasoning path that includes a\ntransition from a negative reasoning node to a positive one.\nIdentifying negative sibling node. Given the effective\nreasoning path Y , we identify the negative sibling reasoning\nnode for s \u2208Y using UCB:\nsneg = arg min\nsl\u2208Sibling(s)\nUCB(sl) \u2212UCB(s), \u2200s \u2208Y,\n(7)\nwhere Sibling(s) returns all the sibling nodes of s, i.e., the\nnodes on the same hierarchical level under the same parent\nnode of s. UCB(s) = V (s) + c \u00b7\nq\nlog N(\u02c6s)\n1+N(s) as in Eq. 6.\nConstructing reflective reasoning path. Based on Eq. 7,\nwe randomly sample a reasoning node s \u2208Y with its\nnegative sibling node sneg, and concatenate them with\na reflection prompt to form a reflection trajectory, i.e.,\n(sneg, promptreflect, s). We then use a function Replace(\u00b7)\nthat replaces s \u2208Y with (sneg, promptreflect, s) to convert Y\ninto the reflective reasoning path Yreflect:\nYreflect = Replace(Y, s, (sneg, promptreflect, s)),\n(8)\nwhere promptreflect denotes a reflection prompt, such as \u201cThe\nprevious reasoning step is wrong and let\u2019s rethink it again.\u201d\nThen, we can integrate the reflective reasoning path Yreflect\ninto our data as a quadruplet {Q, Y, Yreflect, S} \u2208D.\nAlgorithm 1 Training Mulberry with CoMCTS\nInput: a set of policy models {\u03c01, \u03c02, ..., \u03c0K} initialized\nby different MLLMs; a set of multimodal questions DQ\nfor i = 1 to MaxEpoch do\nReasoning Tree Search using CoMCTS:\nfor Q \u2208DQ do\nCollective Monte Carlo tree search:\n{Q, Y, S} = CoMCTS({\u03c01, \u03c02, ..., \u03c0K}; Q)\nif found an effective reasoning path then\nSearch and find Yreflect from S\nAdd {Q, Y, Yreflect, S} into D\nRemove Q from DQ\nModel Training with CoMCTS Reasoning Trees:\nfor k = 1 to K do\nfor (Q, Y, Yreflect, S) \u2208D do\nSupervised Fine-Tuning:\nOptimize \u03c0k via LCoSFT(\u03c0k) and LCoSFT-Re(\u03c0k)\nOutput: Trained policy models {\u03c01, \u03c02, ..., \u03c0K}\n3.3. Training with Collective MCTS\nUsing CoMCTS, we search effective and reflective reason-\ning paths for a set of multimodal input questions, and con-\nstruct Mulberry-260k, a multimodal learning-to-reason-and-\nreflect dataset with a tree of rich, explicit and well-defined\nreasoning nodes for each question, i.e., a set of quadru-",
    "reflect dataset with a tree of rich, explicit and well-defined\nreasoning nodes for each question, i.e., a set of quadru-\nplets {Q, Y, Yreflect, S} \u2208D. To learn collective knowledge\nfrom Mulberry-260k, we perform collective SFT to train\nour model, Mulberry, a series of Multimodal LLMs with\no1-like step-by-step Reasoning and Reflection capabilities.\nCollective Supervised Fine-Tuning (CoSFT). Given\n(Q, Y ) \u2208D, we apply standard SFT objective to train our\nMLLM to learn from D constructed by CoMCTS:\nLCoSFT(\u03c0k) =\nX\n(Q,Y )\u2208D\nlog \u03c0k(Y |Q),\n(9)\nwhere Y = {s} denotes the effective reasoning path that\nincludes a sequence of reasoning nodes collectively conjec-\ntured, searched and identified by a group of MLLMs.\nCoSFT for reflective reasoning. Given a question and its\nreasoning tree (Q, S) \u2208D constructed by CoMCTS, we\nrandomly sample a reflective reasoning path Yreflect from S\n5\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nThe figure shows a triangle \nnamed WZY, with W at the \ntop and Z and Y on a \nhorizontal line at the bottom..\nWe have a triangle WZY with an \naltitude WU drawn to the base ZY. \nThis altitude creates two right \ntriangles: WUZ (on the left)\u2026\nStep1: Apply Pythagorean \ntheorem to \u2220WUZ : \n(3x - 6)2 = WU2 + (x + 6)2\nStep1: Use the Pythagorean \ntheorem in \u2220WUZ : \nWU2 = (3x - 6)2 + (x + 6)2\n. . .\nThe final \nanswer is 18\nLevel 1\nLevel 2\nLevel 3\nLevel N\nGT Answer: 18\nQuestion: \nCalculate the length of ZU\n. . .\nOrange, Blue and Green denote reasoning nodes \ngenerated by different policy models \ud835\udf45\ud835\udfcf , \ud835\udf45\ud835\udfd0 , \ud835\udf45\ud835\udfd1 \nReflection\nFigure 3: Qualitative illustration of reasoning tree searched by CoMCTS with rich, explicit, well-defined reasoning nodes.\nas in Eqs.7-8, and conduct CoSFT for reflective reasoning:\nLCoSFT-Re(\u03c0k) =\nX\n(Q,Yreflect)\u2208D\nlog \u03c0k(Yreflect|Q),\n(10)\nwhere Yreflect = {s} denotes the reflective reasoning path\nthat includes an additional step-wise reflection trajectory.\nThe goal of LCoSFT and LCoSFT-Re is to maximize the log\nprobability of effective and reflective reasoning path Y and\nYreflect over a tree of reasoning nodes S generated by CoM-\nCTS. In addition, LCoSFT-Re enables to leverage the negative\ninformation during CoMCTS search process by learning to\ncalibrate negative reasoning nodes.\n4. Experiment\nIn this section, we first introduce our CoMCTS-generated\ndataset, Mulberry-260K, including its sources, construction,\nand analysis in Section 4.1, and provide implementation\ndetails in Section 4.2. We then present the main results in\nSection 4.3, demonstrating the effectiveness of the searched\ndata (i.e., Mulberry-260K) and the trained models (i.e., Mul-\nberry). In Section 4.4, we perform comprehensive ablation\nstudies on the impact of effective and reflective reasoning\ndata and the contributions of collective knowledge sources.\nIn final, Section 4.5 discuses the effectiveness and efficiency\nof tree search methods, explores different training strategies,\nand provides qualitative comparisons.\n4.1. Dataset\nThe Sources of Raw Data. To construct a comprehensive\nand general-purpose tree-based reasoning dataset, we col-\nlect 260K raw multimodal input questions (i.e., a text task\ninstruction with an image as an input question) from a wide\nrange of domains, covering General Multimodal Under-\nstanding, Mathematics, Figure Understanding, Realworld\nUnderstanding, Science, Medical Image Understanding, etc.",
    "instruction with an image as an input question) from a wide\nrange of domains, covering General Multimodal Under-\nstanding, Mathematics, Figure Understanding, Realworld\nUnderstanding, Science, Medical Image Understanding, etc.\nThe specific data sources are provided in the Appendix A.\nReasoning Data Construction. As detailed in Section 3\nand Algorithm 1 and visually illustrated in Figures 2 and 3,\nwe employ our CoMCTS to search effective and reflective\nreasoning paths for a set of raw multimodal input questions\nas collected from the mentioned \u201cThe Sources of Raw Data\u201d,\nultimately constructing our dataset, Mulberry-260K. Note\nwe only sample 15K data for reflective reasoning training to\navoid overabundance of reflection data.\nReasoning Data Distribution. We analyze the CoMCTS-\nsearched reasoning paths in Mulberry-260K by examining\nthe distribution of reasoning steps, as shown in Figure 4.\nSpecifically, Figure 4 shows that reasoning steps predom-\ninantly falls between 6 and 8, with an average of 7.5, for\nthe entire Mulberry-260k. Meanwhile, for simple reasoning\ntasks, the chart-related subset of Mulberry-260k, reason-\ning steps typically ranges from 6 to 7, averaging 6.8. For\ncomplex mathematical and logical reasoning tasks, such as\nthe geometry-related subset of Mulberry-260k, the distribu-\ntion shifts and largely falls between 7 and 10 steps, with an\naverage of 8.9. These observations highlight that the col-\n6\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nFigure 4: Distribution of reasoning steps in Mulberry-260K data.\nlective tree search design in CoMCTS enables to generate\neffective reasoning trajectories with flexible numbers of rea-\nsoning steps, learning from which allows to train a powerful\nMLLM with great reasoning flexibility, i.e., a model can\n\u201cthink less and faster\u201d when handling simple questions (i.e.,\nallocate and generate fewer intermediate reasoning steps)\nand \u201cthink more and slower\u201d when tackling complex tasks\n(i.e., allocate and generate a greater number of intermediate\nreasoning steps).\n4.2. Implementation Detail\nIn this paper, we implement the collective learning in CoM-\nCTS by employing a group of four models, including GPT-\n4o, Qwen2-VL-7B, LLaMA-3.2-11B-Vision-Instruct, and\nQwen2-VL-72B, to construct Mulberry-260K. In our CoM-\nCTS, we set the maximum search iteration as 20. In each\nsearch iteration, we employ each model from the group to\ngenerate one subsequent candidate reasoning path to balance\nsearch exploration and exploitation. In Simulation and Error\nPositioning in CoMCTS, we simply set threshold t as 0. We\nadopt four popular MLLMs as baseline models, and conduct\nexperiments on baselines Qwen2-VL-7B and LLaMA-3.2-\n11B-Vision-Instruct to examine the search effectiveness of\nour CoMCTS, and on baselines Qwen2-VL-2B and LLaVA-\nNeXT-8B to study the generalization of CoMCTS-searched\ndata. The collective SFT experiments are conducted with a\nbatch size of 128, a learning rate of 1e-5, and training over 2\nepochs. For Qwen2-VL-7B, a smaller learning rate of 5e-6\nis adopted to stabilize the training.\n4.3. Main Results\nTo examine the effectiveness of the searched data (i.e.,\nMulberry-260K) and the trained models (i.e., Mulberry), we\nconduct extensive experiments with four powerful baseline\nmodels, and comprehensively benchmark our Mulberry with\nvarious state-of-the-arts, including general and reasoning-\nbased MLLMs. The evaluation is performed on 8 widely\nused and challenging datasets (Huang & Zhang, 2024), cov-\nering the fields ranging from general and mathematical\nreasoning to hallucination and visual illusion, and multi-\ndisciplinary understanding and reasoning, as shown in Ta-\nble 1.\nComparison with baselines. We first conduct experiments\non baselines Qwen2-VL-7B and LLaMA-3.2-11B-Vision-",
    "ble 1.\nComparison with baselines. We first conduct experiments\non baselines Qwen2-VL-7B and LLaMA-3.2-11B-Vision-\nInstruct that are involved in collective learning of CoMCTS\nfor joint reasoning-path conjecture, search and identification.\nWe can observe that, trained with jointly-searched data (i.e.,\nMulberry-260k), our Mulberry-7B and Mulberry-11B bring\nclear performance improvements against their baselines,\ni.e., +4.2% over Qwen2-VL-7B and +7.5% over LLaMA-\n3.2-11B-Vision-Instruct averaged on 8 benchmarks, vali-\ndating the search effectiveness of our CoMCTS. On the\nother hand, we examine the generalization of our Mulberry-\n260k by applying it to train other models that are not in-\nvolved in collective tree search in CoMCTS, such as Qwen2-\nVL-2B and LLaVA-NeXT-8B. It can be observed that,\ntrained with Mulberry-260k, our models (i.e., Mulberry-\n2B and Mulberry-8B) enhance Qwen2-VL-2B and LLaVA-\nNeXT-8B with +5.4% and +11.0% gains averaged on 8\nbenchmarks, demonstrating the generalization of CoMCTS-\nsearched data.\nComparison with reasoning-response models. We then\nbenchmark our Mulberry with various state-of-the-art\nreasoning-response models. It shows that, using the same\nbase model LLaVA-NeXT-8B (Li et al., 2024), our Mul-\nberry outperforms LLaVA-Reasoner-8B and Insight-V-8B\nby +5.7% and +6.5% on mathematical benchmark Math-\nVista, and by +3.0% and +1.0% on multi-disciplinary bench-\nmark MMMU, respectively. Besides, Mulberry-11B sur-\npasses LLaVA-COT-11B by +6.3% on reasoning-intensive\nbenchmark MathVista under the same baseline LLaMA-3.2-\n11B-Vision-Instruct. The great superiority of Mulberry is\nlargely attributed to our CoMCTS that conducts tree search\nand provides rich, explicit and well-defined reasoning nodes\nwith flexible numbers of steps.\nComparison with state-of-the-arts. In final, we bench-\nmark our Mulberry with popular state-of-the-arts included\nboth open-source and closed-source ones. The results in Ta-\nble 1 show that our Mulberry, trained on CoMCTS-searched\ndata, outperforms most open-sourced MLLMs and achieves\ncompetitive results against closed-source ones, demonstrat-\ning outstanding abilities in step-by-step reasoning and re-\nflection.\n7\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nMethod\nMathVista MMStar MMMU ChartQA DynaMath HallBench MM-Math MMEsum\nAVG\nClosed-Source Model\nGPT-4o (Hurst et al., 2024)\n63.8\n63.9\n69.1\n85.7\n63.7\n55.0\n31.8\n2329\n64.5\nClaude-3.5 Sonnet (Anthropic, 2024)\n67.7\n62.2\n68.3\n90.8\n64.8\n55.0\n-\n1920\n-\nOpen-Source Model\nDeepSeek-VL-7B (Lu et al., 2024a)\n36.1\n37.1\n35.4\n59.1\n21.5\n-\n-\n-\n-\nCambrain-1-8B (Tong et al., 2024)\n49.0\n-\n42.7\n73.3\n-\n-\n-\n-\n-\nMM-1.5-7B (Zhang et al., 2024b)\n47.6\n-\n41.8\n78.6\n-\n-\n-\n1861\n-\nIdefics3-LLaMA3-8B (Lauren\u00e7on et al., 2024)\n58.4\n55.9\n46.6",
    "78.6\n-\n-\n-\n1861\n-\nIdefics3-LLaMA3-8B (Lauren\u00e7on et al., 2024)\n58.4\n55.9\n46.6\n74.8\n-\n-\n-\n1937\n-\nInternVL2-8B (Chen et al., 2024)\n58.3\n61.5\n51.8\n83.3\n39.7\n-\n-\n2210\n-\nMiniCPM-Llama-V-2.5-8B (Yao et al., 2024c)\n54.3\n51.8\n45.8\n-\n-\n42.4\n-\n2025\n-\nMiniCPM-V-2.6-8B (Yao et al., 2024c)\n60.6\n57.5\n49.8\n-\n-\n48.1\n-\n2348\n-\nDeepSeek-VL2-MOE-4.5B (Wu et al., 2024)\n62.8\n61.3\n51.1\n86.0\n-\n-\n-\n2253\n-\nReasoning Model\nLLaVA-CoT-11B (Xu et al., 2024)\n54.8\n57.6\n-\n-\n-\n47.8\n-\n-\n-\nLLaVA-Reasoner-8B (Zhang et al., 2024d)\n50.6\n54.0\n40.0\n83.0\n-\n-\n-\n-\n-\nInsight-V-8B (Dong et al., 2024)\n49.8\n57.4\n42.0\n77.4\n-\n-\n-\n2069\n-\nLLaVA-NeXT-8B (Li et al., 2024)\n37.5\n42.1\n41.7\n69.5\n22.7\n33.4\n0.6\n1957\n39.7\nMulberry-LLaVA-8B\n56.3\n54.5\n43.0\n79.5\n34.1\n47.5\n18.9\n2021\n50.711\u2191\nLlama-3.2-11B-V-Ins. (Dubey et al., 2024)\n48.6\n49.8\n41.7\n83.4\n34.3\n40.3\n4.1\n1787\n45.8\nMulberry-Llama-11B\n61.1\n58.5\n45.6\n83.5\n37.2\n48.9\n18.7\n2035\n53.37.5\u2191\nQwen2-VL-2B (Wang et al., 2024b)\n43.0\n48.0\n41.1\n73.5\n24.9\n41.7\n1.0\n1872\n42.5\nMulberry-2B\n51.7\n51.3\n42.0\n77.7\n30.0\n44.9\n13.9\n2013\n47.95.4\u2191\nQwen2-VL-7B (Wang et al., 2024b)\n58.2\n60.7\n54.1\n83.0\n42.1\n50.6\n5.9\n2327\n54.7\nMulberry-7B\n63.1\n61.3\n55.0\n83.9\n45.1\n54.1\n23.7\n2396\n58.94.2\u2191\nTable 1: Main Results. To examine the effectiveness of the searched data (i.e., Mulberry-260K) and the trained models (i.e.,\nMulberry), we conduct extensive experiments with four powerful baseline models, and comprehensively benchmark our\nMulberry with various state-of-the-arts, including general and reasoning-based MLLMs.\nDirect Pred\nCoMCTS\nS.S.R.\nGPT-4o\nGPT-4o Qwen2-VL-7B LLama3.2-11B Qwen2-VL-72B\n\"\n58.2\n\"\n63.8\n\"\n\"\n66.2\n\"\n\"\n\"\n69.7\n\"\n\"\n\"\n\"\n80.2\nTable 2: Ablation Study on CoMCTS. We study how each\nmodel in CoMCTS collective learning contribute to overall",
    "\"\n\"\n69.7\n\"\n\"\n\"\n\"\n80.2\nTable 2: Ablation Study on CoMCTS. We study how each\nmodel in CoMCTS collective learning contribute to overall\ntree search performance in Search Success Rate (S.S.R.).\n4.4. Ablation Study\nAblation Study on CoMCTS. We conduct ablation studies\nwith the powerful GPT-4o as the baseline over 1K samples\nfrom Geo3K (Lu et al., 2021a) and GeoQA-Plus (Chen\net al., 2021), as shown in Table 2. As the core of our pro-\nposed CoMCTS, we examine how each model in the col-\nlective learning group contribute to the overall tree search\nperformance. Table 2 reports the Search Success Rates\n(S.S.R.). The baseline GPT-4o works not very well without\ntree search. It shows that CoMCTS with only GPT-4o im-\nproves the performance to 63.8%, largely becuase our tree\nsearch designs like expansion, simulation and error posi-\ntioning can work even without using collective knowledge.\nBenchmark\nw/o Reflection Data\nw/ Reflection Data\nMathVista\n50.9\n51.7\nTable 3: Ablation Study on Mulberry. As Mulberry is\ntrained with effective and reflective reasoning data searched\nby CoMCTS, we study their respective contributions.\nBesides, progressively involving more models into CoM-\nCTS consistently improves the search performance, even for\nincluding small models like Qwen2-VL-7B (i.e., +2.4%),\ndemonstrating the effectiveness of CoMCTS in capturing\nuseful collective knowledge not only with large models but\nalso from small models. In final, the inclusion of all four\nmodels in the proposed CoMCTS performs clearly the best,\ni.e.80.2%, validating the effectiveness of collective learning\non reasoning tree search.\nAblation Study on Mulberry. We train Mulberry with ef-\nfective and reflective reasoning data searched by CoMCTS,\nand study their respective contributions to overall reasoning\nperformance. Table 3 presents the results on MathVista,\nwhich show that incorporating reflection data enhances the\nperformance by 0.8%, demonstrating the complementar-\nity of effective and reflective reasoning data searched by\nCoMCTS.\n8\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nMulberry: \n### Image Description: A diagram shows a circular sector \nbeing transformed into a cone without its base. The \nsector has a central angle labeled as 120\u00b0 and a given \nradius length of 6. \n### Rationales: To find the circumference or \"bottom \nperimeter\" of the resulting cone from rolling up this \nsector, we need to understand that when you form a \ncone using such a sector, the arc length becomes the \ncircumference of the base circle of the cone.\n### Let's think step by step. \n### Step 1: Calculate the arc length of the sector which \nforms the circumference of the cone's base. Arc Length = \ncentral angle/360 \u00d7 2\u03c0r. Here, r=6 cm and central angle \n= 120\u00b0.\n### Step 2: Substitute values into the formula: \nArc Length = (120/360) \u00d7 2\u03c0 \u00d7 6.\nSimplify it further to get the actual arc length.\n### Step 3: Perform calculations: Arc Length = 1/3 \u00d7 12\u03c0 \n= 4\u03c0. This means the circumference of the cone's base \nequals 4\u03c0.\n### The final answer is: C\nQuestion: Use a sector \npaper sheet with a \ncentral angle of 120.0 \nand a radius of 6.0 to roll \ninto a conical bottomless \npaper cap (as shown in \nthe picture), then the \nbottom perimeter of the \npaper cap is ()\nChoices: \n(A) 2 \u03c0 cm; (B) 3 \u03c0 cm;\n(C) 4 \u03c0 cm; (D) 5 \u03c0 cm\nQwen2-VL: First, let's find the circumference of the base \nof the cone. The circumference of the base is equal to \nthe length of the arc of the sector paper sheet.\nThe formula for the circumference of a circle is  C = 2 \u03c0 r,",
    "of the cone. The circumference of the base is equal to \nthe length of the arc of the sector paper sheet.\nThe formula for the circumference of a circle is  C = 2 \u03c0 r, \nwhere r is the radius. In this case, the radius of the base \nof the cone is equal to the radius of the sector paper \nsheet, which is 6.0 cm.\nSo, the circumference of the base of the cone is: C = 2 \u03c0 \n\u00d7 6.0 = 12 \u03c0 cm.\nHowever, the question asks for the bottom perimeter of \nthe paper cap, which is the circumference of the base of \nthe cone. Therefore, the bottom perimeter of the paper \ncap is:12 \u03c0 cm.\nSo, the correct answer is D\nCorrect Answer: (C)\nLLaVA: We need to find the derivative of f(x) at x=2 and \ncompare it with the derivative of f(x) at x=5. We can do \nthis by using the power rule of differentiation, which \nstates that if f(x) = x^n, then f'(x) = nx^(n-1). At x=2, f'(2) \n= 2^(n-1) = 2^3 = 8. At x=5, f'(5) = 5^(n-1) = 5^3 = 125.\nTherefore, the derivative of f(x) at x=2 is larger than that \nat x=5. The correct answer is (A).\nFigure 5: Qualitative Comparison. Our Mulberry, trained with CoMCTS-searched reasoning data, creates rich, explicit and\nwell-defined reasoning steps with comprehensive understanding, ultimately arriving at the correct answer.\nMethods\nSearch Success Rate \u2191\nAverage Search Iteration \u2193\nGPT4o (direct)\n58.2\n-\nMCTS\n63.8\n42.1\nReST-MCTS\n65.6\n36.3\nOmega-MCTS\n66.2\n24.3\nCoMCTS\n80.2\n12.7\nTable 4: Comparison with other tree search methods.\n\u201cGPT-4o (direct)\u201d refers to the baseline without tree search.\nOur CoMCTS shows great superiority in search effective-\nness and efficiency.\n4.5. Discussion\nComparison with other tree search methods. We com-\npare our CoMCTS with other tree search methods in search\neffectiveness and efficiency, including the baseline \u201cGPT-4o\ndirection prediction\u201d, \u201ctraditional MCTS (Coulom, 2006)\u201d,\n\u201cReST-MCTS (Zhang et al., 2024a)\u201d that enhances MCTS by\nintroducing partial search, and \u201cOmega-MCTS (Luo et al.,\n2024)\u201d that improves MCTS by designing binary search.\nTable 4 shows the results in search success rate and average\nsearch iteration that indicate search effectiveness and effi-\nciency respectively. We can observe that existing tree search\nmethods improve GPT-4o with limited gains. One main rea-\nson lies in that traditional MCTS methods generally work\nby self-bootstrapping and often get trapped in homogeneous\nlow-quality nodes within the reasoning space of a single\nMLLM. On the other hand, our CoMCTS shows great supe-\nriority in search effectiveness and efficiency, largely thanks\nto the joint expansion mechanism in CoMCTS that allows\nreasoning-path search not only within the reasoning space\nof a given MLLM itself but also among those of others, ben-\nefiting from the synergy of multiple MLLMs while avoiding\nbeing trapped within the reasoning space of a single MLLM.\nQualitative comparison. We provide qualitative compar-\nison of LLaVA-NeXT-8B (Li et al., 2024), Qwen2-VL-\n7B (Wang et al., 2024b), and Mulberry-7B in Figure 5.\nIt shows that LLaVA-NeXT-8B and Qwen2-VL-7B gener-\nate relatively short predictions without thorough thinking,\nleading to incorrect answers. On the contrary, our Mulberry,\ntrained with CoMCTS-searched reasoning data, creates rich,\nexplicit and well-defined reasoning steps with comprehen-\nsive understanding, ultimately arriving at the correct answer.",
    "trained with CoMCTS-searched reasoning data, creates rich,\nexplicit and well-defined reasoning steps with comprehen-\nsive understanding, ultimately arriving at the correct answer.\n5. Conclusion\nThis paper presents CoMCTS, a new learning-to-reason\napproach for MLLMs, which introduces the concept of\ncollective learning into \u201ctree search\u201d for effective and ef-\nficient reasoning-path searching and learning. Based on\nthe proposed CoMCTS, we search effective and reflective\nreasoning paths for a set of multimodal inputs, and construct\nMulberry-260k, a multimodal learning-to-reason-and-reflect\ndataset with a tree of rich, explicit and well-defined reason-\ning nodes for each question. Using Mulberry-260k, we train\nour model, Mulberry, a series of Multimodal LLMs with\no1-like step-by-step Reasoning and Reflection capabilities.\nFurthermore, we conduct extensive experiments, ablation\nstudies and discussion, which demonstrate the superiority\nof our proposed methods on various benchmarks. We hope\nthat CoMCTS along with Mulberry-260k and Mulberry will\nprovides valuable resources and offer new insights for mul-\ntimodal MCTS search and reasoning.\n9\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nReferences\nAnthropic. Claude 3.5 sonnet, 2024. URL https://www.\nanthropic.com/news/claude-3-5-sonnet.\nAntol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D.,\nZitnick, C. L., and Parikh, D. Vqa: Visual question\nanswering. In Proceedings of the IEEE international\nconference on computer vision, pp. 2425\u20132433, 2015.\nBest, G., Cliff, O. M., Patten, T., Mettu, R. R., and Fitch,\nR. Dec-mcts: Decentralized planning for multi-robot\nactive perception. The International Journal of Robotics\nResearch, 38(2-3):316\u2013337, 2019.\nBesta, M., Blach, N., Kubicek, A., Gerstenberger, R., Pod-\nstawski, M., Gianinazzi, L., Gajda, J., Lehmann, T.,\nNiewiadomski, H., Nyczyk, P., et al. Graph of thoughts:\nSolving elaborate problems with large language models.\nIn Proceedings of the AAAI Conference on Artificial In-\ntelligence, volume 38, pp. 17682\u201317690, 2024.\nBlum, A. and Mitchell, T. Combining labeled and unlabeled\ndata with co-training. In Proceedings of the eleventh\nannual conference on Computational learning theory, pp.\n92\u2013100, 1998.\nChen, J., Tang, J., Qin, J., Liang, X., Liu, L., Xing, E. P., and\nLin, L. Geoqa: A geometric question answering bench-\nmark towards multimodal numerical reasoning. arXiv\npreprint arXiv:2105.14517, 2021.\nChen, J., Li, T., Qin, J., Lu, P., Lin, L., Chen, C., and Liang,\nX. Unigeo: Unifying geometry logical reasoning via\nreformulating mathematical expression. arXiv preprint\narXiv:2212.02746, 2022.\nChen, Z., Wang, W., Tian, H., Ye, S., Gao, Z., Cui, E.,\nTong, W., Hu, K., Luo, J., Ma, Z., et al. How far are\nwe to gpt-4v?\nclosing the gap to commercial multi-\nmodal models with open-source suites. arXiv preprint\narXiv:2404.16821, 2024.\nCoulom, R. Efficient selectivity and backup operators in\nmonte-carlo tree search. In International conference on\ncomputers and games, pp. 72\u201383. Springer, 2006.\nCui, K., Huang, J., Luo, Z., Zhang, G., Zhan, F., and Lu, S.\nGenco: Generative co-training for generative adversarial",
    "Cui, K., Huang, J., Luo, Z., Zhang, G., Zhan, F., and Lu, S.\nGenco: Generative co-training for generative adversarial\nnetworks with limited data. In Proceedings of the AAAI\nConference on Artificial Intelligence, volume 36, pp. 499\u2013\n507, 2022.\nDam, T., Chalvatzaki, G., Peters, J., and Pajarinen, J. Monte-\ncarlo robot path planning. IEEE Robotics and Automation\nLetters, 7(4):11213\u201311220, 2022.\nDong, Y., Liu, Z., Sun, H.-L., Yang, J., Hu, W., Rao, Y., and\nLiu, Z. Insight-v: Exploring long-chain visual reasoning\nwith multimodal large language models. arXiv preprint\narXiv:2411.14432, 2024.\nDubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle,\nA., Letman, A., Mathur, A., Schelten, A., Yang, A., Fan,\nA., et al. The llama 3 herd of models. arXiv preprint\narXiv:2407.21783, 2024.\nFawzi, A., Balog, M., Huang, A., Hubert, T., Romera-\nParedes, B., Barekatain, M., Novikov, A., R Ruiz, F. J.,\nSchrittwieser, J., Swirszcz, G., et al.\nDiscovering\nfaster matrix multiplication algorithms with reinforce-\nment learning. Nature, 610(7930):47\u201353, 2022.\nFoerster, J., Assael, I. A., De Freitas, N., and Whiteson,\nS. Learning to communicate with deep multi-agent re-\ninforcement learning. Advances in neural information\nprocessing systems, 29, 2016.\nGao, J., Pi, R., Zhang, J., Ye, J., Zhong, W., Wang, Y., Hong,\nL., Han, J., Xu, H., Li, Z., et al. G-llava: Solving geo-\nmetric problem with multi-modal large language model.\narXiv preprint arXiv:2312.11370, 2023.\nGoyal, Y., Khot, T., Summers-Stay, D., Batra, D., and\nParikh, D. Making the v in vqa matter: Elevating the\nrole of image understanding in visual question answer-\ning. In Proceedings of the IEEE conference on computer\nvision and pattern recognition, pp. 6904\u20136913, 2017.\nGurari, D., Li, Q., Stangl, A. J., Guo, A., Lin, C., Grauman,\nK., Luo, J., and Bigham, J. P. Vizwiz grand challenge:\nAnswering visual questions from blind people. In Pro-\nceedings of the IEEE conference on computer vision and\npattern recognition, pp. 3608\u20133617, 2018.\nHuang, J. and Zhang, J.\nA survey on evaluation of\nmultimodal large language models.\narXiv preprint\narXiv:2408.15769, 2024.\nHurst, A., Lerer, A., Goucher, A. P., Perelman, A., Ramesh,\nA., Clark, A., Ostrow, A., Welihinda, A., Hayes, A.,\nRadford, A., et al. Gpt-4o system card. arXiv preprint\narXiv:2410.21276, 2024.\nJohnson, J., Hariharan, B., Van Der Maaten, L., Fei-Fei,\nL., Lawrence Zitnick, C., and Girshick, R. Clevr: A\ndiagnostic dataset for compositional language and ele-\nmentary visual reasoning. In Proceedings of the IEEE\nconference on computer vision and pattern recognition,\npp. 2901\u20132910, 2017.\nKafle, K., Price, B., Cohen, S., and Kanan, C. Dvqa: Under-\nstanding data visualizations via question answering. In\nProceedings of the IEEE conference on computer vision\nand pattern recognition, pp. 5648\u20135656, 2018.\n10",
    "standing data visualizations via question answering. In\nProceedings of the IEEE conference on computer vision\nand pattern recognition, pp. 5648\u20135656, 2018.\n10\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nKahou, S. E., Michalski, V., Atkinson, A., K\u00e1d\u00e1r, \u00c1.,\nTrischler, A., and Bengio, Y.\nFigureqa: An anno-\ntated figure dataset for visual reasoning. arXiv preprint\narXiv:1710.07300, 2017.\nKazemi, M., Alvari, H., Anand, A., Wu, J., Chen, X.,\nand Soricut, R. Geomverse: A systematic evaluation\nof large models for geometric reasoning. arXiv preprint\narXiv:2312.12241, 2023.\nKembhavi, A., Salvato, M., Kolve, E., Seo, M., Hajishirzi,\nH., and Farhadi, A. A diagram is worth a dozen images.\nIn Computer Vision\u2013ECCV 2016: 14th European Confer-\nence, Amsterdam, The Netherlands, October 11\u201314, 2016,\nProceedings, Part IV 14, pp. 235\u2013251. Springer, 2016.\nKembhavi, A., Seo, M., Schwenk, D., Choi, J., Farhadi, A.,\nand Hajishirzi, H. Are you smarter than a sixth grader?\ntextbook question answering for multimodal machine\ncomprehension. In Proceedings of the IEEE Conference\non Computer Vision and Pattern recognition, pp. 4999\u2013\n5007, 2017.\nLample, G., Lacroix, T., Lachaux, M.-A., Rodriguez, A.,\nHayat, A., Lavril, T., Ebner, G., and Martinet, X. Hyper-\ntree proof search for neural theorem proving. Advances in\nneural information processing systems, 35:26337\u201326349,\n2022.\nLau, J. J., Gayen, S., Ben Abacha, A., and Demner-\nFushman, D. A dataset of clinically generated visual\nquestions and answers about radiology images. Scientific\ndata, 5(1):1\u201310, 2018.\nLauren\u00e7on, H., Marafioti, A., Sanh, V., and Tronchon, L.\nBuilding and better understanding vision-language mod-\nels: insights and future directions. In Workshop on Re-\nsponsibly Building the Next Generation of Multimodal\nFoundational Models, 2024.\nLi, B., Zhang, K., Zhang, H., Guo, D., Zhang, R.,\nLi, F., Zhang, Y., Liu, Z., and Li, C.\nLlava-\nnext:\nStronger\nllms\nsupercharge\nmultimodal\ncapabilities\nin\nthe\nwild,\nMay\n2024.\nURL\nhttps://llava-vl.github.io/blog/\n2024-05-10-llava-next-stronger-llms/.\nLi, Z., Wang, X., Stengel-Eskin, E., Kortylewski, A., Ma,\nW., Van Durme, B., and Yuille, A. L. Super-clevr: A vir-\ntual benchmark to diagnose domain robustness in visual\nreasoning. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, pp. 14963\u2013\n14973, 2023.\nLindstr\u00f6m, A. D. and Abraham, S. S. Clevr-math: A dataset\nfor compositional language, visual and mathematical rea-\nsoning. arXiv preprint arXiv:2208.05358, 2022.\nLiu, F., Lin, K., Li, L., Wang, J., Yacoob, Y., and Wang, L.\nMitigating hallucination in large multi-modal models via\nrobust instruction tuning. In The Twelfth International\nConference on Learning Representations, 2023.\nLiu, H., Li, C., Wu, Q., and Lee, Y. J. Visual instruction tun-\ning. Advances in neural information processing systems,\n36, 2024.\nLu, H., Liu, W., Zhang, B., Wang, B., Dong, K., Liu, B.,",
    "ing. Advances in neural information processing systems,\n36, 2024.\nLu, H., Liu, W., Zhang, B., Wang, B., Dong, K., Liu, B.,\nSun, J., Ren, T., Li, Z., Yang, H., et al. Deepseek-vl:\ntowards real-world vision-language understanding. arXiv\npreprint arXiv:2403.05525, 2024a.\nLu, P., Gong, R., Jiang, S., Qiu, L., Huang, S., Liang, X.,\nand Zhu, S.-C. Inter-gps: Interpretable geometry problem\nsolving with formal language and symbolic reasoning. In\nThe 59th Annual Meeting of the Association for Compu-\ntational Linguistics (ACL), 2021a.\nLu, P., Qiu, L., Chen, J., Xia, T., Zhao, Y., Zhang, W., Yu,\nZ., Liang, X., and Zhu, S.-C. Iconqa: A new benchmark\nfor abstract diagram understanding and visual language\nreasoning. arXiv preprint arXiv:2110.13214, 2021b.\nLu, P., Mishra, S., Xia, T., Qiu, L., Chang, K.-W., Zhu,\nS.-C., Tafjord, O., Clark, P., and Kalyan, A. Learn to\nexplain: Multimodal reasoning via thought chains for\nscience question answering. Advances in Neural Infor-\nmation Processing Systems, 35:2507\u20132521, 2022a.\nLu, P., Qiu, L., Chang, K.-W., Wu, Y. N., Zhu, S.-C., Ra-\njpurohit, T., Clark, P., and Kalyan, A. Dynamic prompt\nlearning via policy gradient for semi-structured math-\nematical reasoning. arXiv preprint arXiv:2209.14610,\n2022b.\nLu, S., Li, Y., Chen, Q.-G., Xu, Z., Luo, W., Zhang, K.,\nand Ye, H.-J. Ovis: Structural embedding alignment\nfor multimodal large language model. arXiv preprint\narXiv:2405.20797, 2024b.\nLuan, B., Feng, H., Chen, H., Wang, Y., Zhou, W., and Li,\nH. Textcot: Zoom in for enhanced multimodal text-rich\nimage understanding. arXiv preprint arXiv:2404.09797,\n2024.\nLuo, L., Liu, Y., Liu, R., Phatale, S., Lara, H., Li, Y., Shu,\nL., Zhu, Y., Meng, L., Sun, J., et al. Improve mathemati-\ncal reasoning in language models by automated process\nsupervision. arXiv preprint arXiv:2406.06592, 2024.\nMasry, A., Long, D. X., Tan, J. Q., Joty, S., and Hoque,\nE. Chartqa: A benchmark for question answering about\ncharts with visual and logical reasoning. arXiv preprint\narXiv:2203.10244, 2022.\n11\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nMathew, M., Karatzas, D., and Jawahar, C. Docvqa: A\ndataset for vqa on document images. In Proceedings\nof the IEEE/CVF winter conference on applications of\ncomputer vision, pp. 2200\u20132209, 2021.\nMathew, M., Bagal, V., Tito, R., Karatzas, D., Valveny,\nE., and Jawahar, C. Infographicvqa. In Proceedings\nof the IEEE/CVF Winter Conference on Applications of\nComputer Vision, pp. 1697\u20131706, 2022.\nMethani, N., Ganguly, P., Khapra, M. M., and Kumar, P.\nPlotqa: Reasoning over scientific plots. In Proceedings\nof the IEEE/CVF Winter Conference on Applications of\nComputer Vision, pp. 1527\u20131536, 2020.\nMitra, C., Huang, B., Darrell, T., and Herzig, R. Composi-\ntional chain-of-thought prompting for large multimodal\nmodels. In Proceedings of the IEEE/CVF Conference",
    "Mitra, C., Huang, B., Darrell, T., and Herzig, R. Composi-\ntional chain-of-thought prompting for large multimodal\nmodels. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, pp. 14420\u2013\n14431, 2024.\nOpenAI. Introducing openai o1, 2024. URL https://\nopenai.com/o1/.\nPitanov, Y., Skrynnik, A., Andreychuk, A., Yakovlev, K.,\nand Panov, A. Monte-carlo tree search for multi-agent\npathfinding: Preliminary results. In International Confer-\nence on Hybrid Artificial Intelligence Systems, pp. 649\u2013\n660. Springer, 2023.\nQiao, S., Shen, W., Zhang, Z., Wang, B., and Yuille, A.\nDeep co-training for semi-supervised image recognition.\nIn Proceedings of the european conference on computer\nvision (eccv), pp. 135\u2013152, 2018.\nSaito, K., Watanabe, K., Ushiku, Y., and Harada, T. Max-\nimum classifier discrepancy for unsupervised domain\nadaptation.\nIn Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition, pp. 3723\u2013\n3732, 2018.\nSchwenk, D., Khandelwal, A., Clark, C., Marino, K., and\nMottaghi, R. A-okvqa: A benchmark for visual ques-\ntion answering using world knowledge. In European\nconference on computer vision, pp. 146\u2013162. Springer,\n2022.\nSeo, M., Hajishirzi, H., Farhadi, A., Etzioni, O., and Mal-\ncolm, C. Solving geometry problems: Combining text\nand diagram interpretation. In Proceedings of the 2015\nconference on empirical methods in natural language\nprocessing, pp. 1466\u20131476, 2015.\nShi, W., Hu, Z., Bin, Y., Liu, J., Yang, Y., Ng, S.-K., Bing,\nL., and Lee, R. K.-W. Math-llava: Bootstrapping mathe-\nmatical reasoning for multimodal large language models.\narXiv preprint arXiv:2406.17294, 2024.\nSilver, D., Schrittwieser, J., Simonyan, K., Antonoglou,\nI., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M.,\nBolton, A., et al. Mastering the game of go without\nhuman knowledge. nature, 550(7676):354\u2013359, 2017.\nSingh, A., Natarajan, V., Shah, M., Jiang, Y., Chen, X.,\nBatra, D., Parikh, D., and Rohrbach, M. Towards vqa\nmodels that can read. In Proceedings of the IEEE/CVF\nconference on computer vision and pattern recognition,\npp. 8317\u20138326, 2019.\nSun, S. and Jin, F. Robust co-training. International Journal\nof Pattern Recognition and Artificial Intelligence, 25(07):\n1113\u20131126, 2011.\nTong, S., Brown, E., Wu, P., Woo, S., Middepogu, M.,\nAkula, S. C., Yang, J., Yang, S., Iyer, A., Pan, X., et al.\nCambrian-1: A fully open, vision-centric exploration of\nmultimodal llms. arXiv preprint arXiv:2406.16860, 2024.\nVagadia, H., Chopra, M., Barnawal, A., Banerjee, T., Tuli,\nS., Chakraborty, S., and Paul, R. Phyplan: Composi-\ntional and adaptive physical task reasoning with physics-\ninformed skill networks for robot manipulators. arXiv\npreprint arXiv:2402.15767, 2024.\nWang, K., Pan, J., Shi, W., Lu, Z., Zhan, M., and Li, H. Mea-\nsuring multimodal mathematical reasoning with math-\nvision dataset. arXiv preprint arXiv:2402.14804, 2024a.",
    "suring multimodal mathematical reasoning with math-\nvision dataset. arXiv preprint arXiv:2402.14804, 2024a.\nWang, P., Bai, S., Tan, S., Wang, S., Fan, Z., Bai, J., Chen,\nK., Liu, X., Wang, J., Ge, W., et al. Qwen2-vl: Enhancing\nvision-language model\u2019s perception of the world at any\nresolution. arXiv preprint arXiv:2409.12191, 2024b.\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi,\nE., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting\nelicits reasoning in large language models. Advances in\nneural information processing systems, 35:24824\u201324837,\n2022.\nWu, Z., Chen, X., Pan, Z., Liu, X., Liu, W., Dai, D., Gao, H.,\nMa, Y., Wu, C., Wang, B., et al. Deepseek-vl2: Mixture-\nof-experts vision-language models for advanced multi-\nmodal understanding. arXiv preprint arXiv:2412.10302,\n2024.\nXie, Y., Goyal, A., Zheng, W., Kan, M.-Y., Lillicrap, T. P.,\nKawaguchi, K., and Shieh, M. Monte carlo tree search\nboosts reasoning via iterative preference learning. arXiv\npreprint arXiv:2405.00451, 2024.\nXu, G., Jin, P., Hao, L., Song, Y., Sun, L., and Yuan, L.\nLlava-o1: Let vision language models reason step-by-\nstep. arXiv preprint arXiv:2411.10440, 2024.\nYang, F. An integrated framework integrating monte carlo\ntree search and supervised learning for train timetabling\nproblem. arXiv preprint arXiv:2311.00971, 2023.\n12\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nYao, H., Wu, W., Yang, T., Song, Y., Zhang, M., Feng,\nH., Sun, Y., Li, Z., Ouyang, W., and Wang, J. Dense\nconnector for mllms. arXiv preprint arXiv:2405.13800,\n2024a.\nYao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y.,\nand Narasimhan, K. Tree of thoughts: Deliberate problem\nsolving with large language models. Advances in Neural\nInformation Processing Systems, 36, 2024b.\nYao, Y., Yu, T., Zhang, A., Wang, C., Cui, J., Zhu, H., Cai, T.,\nLi, H., Zhao, W., He, Z., et al. Minicpm-v: A gpt-4v level\nmllm on your phone. arXiv preprint arXiv:2408.01800,\n2024c.\nYe, W., Liu, S., Kurutach, T., Abbeel, P., and Gao, Y. Mas-\ntering atari games with limited data. Advances in neural\ninformation processing systems, 34:25476\u201325488, 2021.\nYu, S., Krishnapuram, B., Rosales, R., and Rao, R. B.\nBayesian co-training. The Journal of Machine Learn-\ning Research, 12:2649\u20132680, 2011.\nYu, T., Yao, Y., Zhang, H., He, T., Han, Y., Cui, G., Hu,\nJ., Liu, Z., Zheng, H.-T., Sun, M., et al. Rlhf-v: To-\nwards trustworthy mllms via behavior alignment from\nfine-grained correctional human feedback. In Proceed-\nings of the IEEE/CVF Conference on Computer Vision\nand Pattern Recognition, pp. 13807\u201313816, 2024.\nYue, X., Zheng, T., Ni, Y., Wang, Y., Zhang, K., Tong, S.,",
    "and Pattern Recognition, pp. 13807\u201313816, 2024.\nYue, X., Zheng, T., Ni, Y., Wang, Y., Zhang, K., Tong, S.,\nSun, Y., Yu, B., Zhang, G., Sun, H., et al. Mmmu-pro: A\nmore robust multi-discipline multimodal understanding\nbenchmark. arXiv preprint arXiv:2409.02813, 2024.\nZelikman, E., Wu, Y., Mu, J., and Goodman, N. Star: Boot-\nstrapping reasoning with reasoning. Advances in Neural\nInformation Processing Systems, 35:15476\u201315488, 2022.\nZhang, D., Zhoubian, S., Hu, Z., Yue, Y., Dong, Y., and\nTang, J. Rest-mcts*: Llm self-training via process reward\nguided tree search. arXiv preprint arXiv:2406.03816,\n2024a.\nZhang, H., Gao, M., Gan, Z., Dufter, P., Wenzel, N., Huang,\nF., Shah, D., Du, X., Zhang, B., Li, Y., et al. Mm1.\n5: Methods, analysis & insights from multimodal llm\nfine-tuning. arXiv preprint arXiv:2409.20566, 2024b.\nZhang, J., Huang, J., Jin, S., and Lu, S. Vision-language\nmodels for vision tasks: A survey. IEEE Transactions on\nPattern Analysis and Machine Intelligence, 2024c.\nZhang, R., Zhang, B., Li, Y., Zhang, H., Sun, Z., Gan, Z.,\nYang, Y., Pang, R., and Yang, Y. Improve vision lan-\nguage model chain-of-thought reasoning. arXiv preprint\narXiv:2410.16198, 2024d.\nZhang, X., Wu, C., Zhao, Z., Lin, W., Zhang, Y., Wang,\nY., and Xie, W.\nPmc-vqa: Visual instruction tuning\nfor medical visual question answering. arXiv preprint\narXiv:2305.10415, 2023.\nZhao, Y., Li, Y., Li, C., and Zhang, R. Multihiertt: Numeri-\ncal reasoning over multi hierarchical tabular and textual\ndata. arXiv preprint arXiv:2206.01347, 2022.\n13\nMulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\nA. The Sources of Raw Data\nTo construct a comprehensive and general-purpose tree-based reasoning dataset, we collect 260K raw multimodal input\nquestions spanning varouis domain, including\n\u2022 55K Mathematical Data: From GLLaVA (Gao et al., 2023), GEOS (Seo et al., 2015), UniGeo (Chen et al., 2022),\nGeoQA Plus (Chen et al., 2021), Geo3K (Lu et al., 2021a), MathVision (Wang et al., 2024a), GeoMverse (Kazemi\net al., 2023), and MathV360K (Shi et al., 2024).\n\u2022 116K Figure Understanding data: From DVQA (Kafle et al., 2018), DocVQA (Mathew et al., 2021), FigureQA (Ka-\nhou et al., 2017), PlotQA (Methani et al., 2020), ChartQA (Masry et al., 2022), InfoVQA (Mathew et al., 2022),\nMultiHiertt (Zhao et al., 2022), and LRV-Chart (Liu et al., 2023).\n\u2022 41K Math Word Problem Data: From IconQA (Lu et al., 2021b), TabMWP (Lu et al., 2022b), CLEVR (Johnson et al.,\n2017), CLEVR-Math (Lindstr\u00f6m & Abraham, 2022), and Super-CLEVR (Li et al., 2023).\n\u2022 2K Mdeical Data: From VQA-RAD (Lau et al., 2018), and PMC-VQA (Zhang et al., 2023).\n\u2022 17K Sience Data: From TQA (Kembhavi et al., 2017), AI2D (Kembhavi et al., 2016), and ScienceQA (Lu et al.,",
    "\u2022 17K Sience Data: From TQA (Kembhavi et al., 2017), AI2D (Kembhavi et al., 2016), and ScienceQA (Lu et al.,\n2022a).\n\u2022 24K Nature World QA Data: From VQA-AS (Antol et al., 2015), A-OKVQA (Schwenk et al., 2022), TextVQA (Singh\net al., 2019), Vizwiz (Gurari et al., 2018), and VQA2.0 (Goyal et al., 2017).\n14"
]