[
    {
        "question_id": "2412.18319v2_0",
        "answer": "The paper identifies key shortcomings of current Multimodal Large Language Models (MLLMs) in handling complex tasks:\n\n1.  **Limited Reasoning Depth:** MLLMs often struggle with tasks requiring in-depth reasoning due to their tendency to operate in a \"direct prediction\" mode, providing brief final answers without explicit intermediate steps.\n\n2.  **Search Effectiveness:** Traditional **Monte Carlo Tree Search (MCTS)** methods, which rely on self-bootstrapping, are ineffective for MLLMs. This is because MLLMs are trained with limited explicit reasoning steps, causing the search to become trapped in homogeneous, low-quality nodes and resulting in low **search success rates**.\n\n3.  **Search Efficiency:** Traditional **MCTS** methods explore only one subsequent reasoning node per iteration, making them computationally inefficient for MLLMs, which are computationally intensive.\n\nTo address these failures, the paper proposes **Collective Monte Carlo Tree Search (CoMCTS)**, a new learning-to-reason method designed to improve both the effectiveness and efficiency of reasoning-path searching and learning in MLLMs.\n\n1.  **Addressing Limited Reasoning Depth:** **CoMCTS** aims to enable MLLMs to create each intermediate step of reasoning until reaching the final answer.\n\n2.  **Enhancing Search Effectiveness:** **CoMCTS** uses a joint expansion mechanism that combines reasoning trajectories from multiple MLLMs. This creates a unified reasoning tree with diverse nodes, enabling search across multiple MLLM reasoning spaces and preventing the search from being trapped in low-quality nodes.\n\n3.  **Improving Search Efficiency:** The joint simulation and error positioning mechanism in **CoMCTS** allows the search to skip multiple intermediate steps, selecting the last correct step as the next starting point. Additionally, collective knowledge helps in identifying and positioning errors.\n\nBy using **CoMCTS**, the authors construct **Mulberry-260k**, a multimodal dataset with a tree of reasoning nodes for each question, and train the **Mulberry** model."
    },
    {
        "question_id": "2412.18319v2_1",
        "answer": "**Collective Monte Carlo Tree Search (CoMCTS)** is a novel learning-to-reason method designed for Multimodal Large Language Models (MLLMs). It enhances the reasoning capabilities of MLLMs by integrating the concept of collective learning into the traditional Monte Carlo Tree Search (MCTS) framework. The core idea behind CoMCTS is to leverage collective knowledge from multiple MLLMs to collaboratively explore, search, and identify effective reasoning paths, ultimately leading to more accurate and comprehensive answers.\n\n***\n\nHere's a breakdown of the key differences between CoMCTS and traditional MCTS in the context of reasoning path search:\n\n### 1. Joint Expansion Mechanism:\n\n*   **CoMCTS:** Employs a joint expansion mechanism that allows it to concatenate reasoning trajectories from multiple MLLMs through iterative search. This approach constructs a unified reasoning tree that comprises a diverse set of complementary reasoning nodes. The search benefits from the synergy of multiple MLLMs, avoiding the pitfalls of being confined to the reasoning space of a single MLLM.\n*   **Traditional MCTS:** Typically expands and explores only one subsequent reasoning node per search iteration, advancing a single step at a time. This can be computationally inefficient for MLLMs, as it requires a massive number of iterations to explore the reasoning space comprehensively.\n\n### 2. Joint Simulation and Error Positioning:\n\n*   **CoMCTS:** Uses collective knowledge to jointly estimate the potential value of child nodes. It identifies low-score nodes as erroneous reasoning steps, filtering them out along with their child nodes. This mechanism allows CoMCTS to skip multiple intermediate steps in each search iteration, selecting the last correct step as the next starting point, which significantly reduces search time while maintaining effectiveness.\n*   **Traditional MCTS:** Often relies on a single model to recognize and position errors, which can be challenging since a model may struggle to identify its own mistakes.\n\n### 3. Reasoning Space:\n\n*   **CoMCTS:** Searches reasoning paths not only within the reasoning space of a given MLLM but also among those of other MLLMs. This broader scope allows for a more comprehensive exploration of potential solutions.\n*   **Traditional MCTS:** Primarily operates within the reasoning space of a single MLLM, which can limit the diversity and quality of the explored reasoning paths.\n\n### 4. Learning from Reflective Reasoning Paths:\n\n*   **CoMCTS:** Extends its capabilities to reflective reasoning-path search. It integrates negative sibling nodes into effective reasoning paths to build reflective reasoning paths that include a transition from a negative reasoning node to a positive one. By learning from these paths, MLLMs can dynamically adjust their reasoning trajectory from erroneous nodes toward correct ones during long-chain reasoning.\n*   **Traditional MCTS:** Does not inherently incorporate mechanisms for reflective reasoning or the integration of negative reasoning paths into the learning process.\n\n### 5. Addressing Limitations of MLLMs:\n\n*   **CoMCTS:** Addresses the limitations of current MLLMs, which are often trained with limited explicit and well-defined intermediate reasoning steps. This helps to prevent the search from being trapped in homogeneous, low-quality nodes.\n*   **Traditional MCTS:** May struggle with MLLMs that lack well-defined reasoning steps, leading to lower search success rates."
    },
    {
        "question_id": "2412.18319v2_2",
        "answer": "The Collective Monte Carlo Tree Search (CoMCTS) algorithm iteratively searches for effective reasoning paths using four key operations. Here's a breakdown of each operation and its contribution:\n\n### 1. Expansion\n\n*   **Goal:** To broaden the search space by generating new candidate reasoning nodes from the current leaf node.\n*   **Process:** Using a group of Multimodal Large Language Models (MLLMs), the algorithm expands the current leaf node by generating a set of diverse and complementary candidate reasoning paths. This is done in parallel until a terminal node is reached.\n*   **Contribution:** Expansion introduces variability and explores different potential reasoning steps, increasing the likelihood of discovering a correct or more efficient path.\n\n***\n\n### 2. Simulation and Error Positioning\n\n*   **Goal:** To evaluate the potential value of newly added child nodes and filter out erroneous reasoning steps.\n*   **Process:** The algorithm estimates the value of each child node using collective knowledge from a group of MLLMs. Nodes with low scores are considered erroneous and are removed, along with their child nodes.\n*   **Contribution:** This step helps to prune the search tree by eliminating unpromising or incorrect reasoning paths, focusing computational resources on more viable options.\n\n***\n\n### 3. Backpropagation\n\n*   **Goal:** To update the statistics of nodes along the newly expanded path, reflecting the results of the simulation.\n*   **Process:** Starting from the leaf nodes, the algorithm updates the visit count and node value of each node in the expanded path. The node value is updated based on the evaluation scores of its children.\n*   **Contribution:** Backpropagation propagates the rewards or penalties from the simulation step back through the tree, allowing the algorithm to learn which paths are more likely to lead to correct answers.\n\n***\n\n### 4. Selection\n\n*   **Goal:** To choose the most promising node to expand in the next iteration.\n*   **Process:** The algorithm traverses the updated reasoning tree and selects the next starting node based on the Upper Confidence Bound (**UCB**) value. The **UCB** value balances exploration and exploitation, encouraging the algorithm to explore less-visited nodes while also exploiting nodes with high reward values.\n*   **Contribution:** Selection guides the search process by focusing on nodes that have the potential to lead to better solutions, balancing the need to explore new paths with the desire to exploit known good paths. The formula for **UCB** is:\n\n    $sk^*_m = arg max_{s\u2208S^*candidate} V(s) + c \\cdot \\sqrt{\frac{log N(s\u02c6)}{1 + N(s)}}$\n\n    where:\n\n    *   $V(s)$ is the node reward value\n    *   $N(s)$ is the visit count\n    *   $c$ is a constant controlling exploration\n    *   $s\u02c6$ denotes the parent node of $s$\n\n***\n\nBy repeating these four operations iteratively, CoMCTS constructs a question-dependent reasoning tree, effectively learning and refining reasoning paths toward the correct answer."
    },
    {
        "question_id": "2412.18319v2_3",
        "answer": "Okay, I will explain how **CoMCTS** integrates negative sibling nodes into reasoning paths for reflective reasoning, and why this benefits **MLLMs**.\n\n***\n\n**CoMCTS** enhances reflective reasoning in **MLLMs** by strategically incorporating negative sibling nodes into the reasoning process. Here's a breakdown:\n\n1.  **Identifying Negative Sibling Nodes**:\n\n    *   After **CoMCTS** constructs a reasoning tree, it identifies negative sibling nodes for each step in the effective reasoning path.\n    *   A negative sibling node is a node at the same hierarchical level as a correct reasoning step but represents an incorrect or less optimal reasoning choice.\n    *   The algorithm uses the **Upper Confidence Bound (UCB)** to find these nodes, specifically looking for nodes with a lower **UCB** value compared to their correct siblings. This is done using the following equation:\n\n        $s^{neg} = arg \\min_{s_l \\in Sibling(s)} UCB(s_l) - UCB(s), \forall s \\in Y$\n\n        Where:\n\n        *   $s^{neg}$ is the negative sibling node.\n        *   $Sibling(s)$ returns all sibling nodes of $s$.\n        *   $UCB(s)$ is the **Upper Confidence Bound** of node $s$.\n\n2.  **Constructing Reflective Reasoning Paths**:\n\n    *   Once a negative sibling node is identified, the method constructs a reflective reasoning path.\n    *   It samples a reasoning node from the effective reasoning path and concatenates it with its negative sibling node, along with a reflection prompt.\n    *   This creates a trajectory that transitions from an incorrect reasoning step to a correct one, encouraging the model to \"rethink\" its approach.\n    *   The original reasoning step is replaced with the sequence (negative sibling node, reflection prompt, correct node) to form the reflective reasoning path ($Y^{reflect}$).\n    *   This replacement is mathematically represented as:\n\n        $Y^{reflect} = Replace(Y, s, (s^{neg}, prompt^{reflect}, s))$\n\n        Where:\n\n        *   $Y$ is the original effective reasoning path.\n        *   $s$ is the reasoning node being replaced.\n        *   $s^{neg}$ is the negative sibling node.\n        *   $prompt^{reflect}$ is a reflection prompt (e.g., \"The previous reasoning step is wrong and let's rethink it again.\").\n\n3.  **Training with Reflective Reasoning Paths**:\n\n    *   The **MLLM** is then trained using these reflective reasoning paths.\n    *   This training involves a **CoSFT** (**Collective Supervised Fine-Tuning**) objective that encourages the model to learn from both the correct and incorrect reasoning steps.\n\n        $L_{CoSFT-Re}(\\pi_k) = - \\sum_{(Q, Y^{reflect}) \\in D} log \\pi_k(Y^{reflect} | Q)$\n\n        Where:\n\n        *   $\\pi_k$ is the policy model.\n        *   $Q$ is the input question.\n        *   $Y^{reflect}$ is the reflective reasoning path.\n        *   $D$ is the dataset.\n\n***\n\nThe benefits of this approach for **MLLMs** are:\n\n*   **Error Correction**: By explicitly exposing the model to incorrect reasoning steps and prompting it to correct them, **CoMCTS** helps the **MLLM** learn to identify and rectify its own errors.\n*   **Robustness**: Training with reflective reasoning paths makes the **MLLM** more robust to noisy or ambiguous inputs, as it learns to navigate away from incorrect reasoning paths.\n*   **Improved Reasoning**: The model develops a better understanding of the reasoning process by contrasting correct and incorrect steps, leading to more accurate and reliable reasoning abilities.\n*   **Dynamic Calibration**: The **MLLM** can dynamically adjust its reasoning trajectory during long-chain reasoning, allowing it to recover from errors and arrive at the correct solution.\n*   **Effective Reflection**: This method facilitates effective step-wise reflection, enabling the **MLLM** to calibrate its reasoning process and improve overall performance."
    },
    {
        "question_id": "2412.18319v2_4",
        "answer": "**Mulberry-260K** is a novel dataset created using Collective Monte Carlo Tree Search (**CoMCTS**) specifically designed to train Multimodal Large Language Models (**MLLMs**) for enhanced reasoning and reflection. It comprises 260,000 raw multimodal input questions, each paired with effective and reflective reasoning paths generated by the **CoMCTS** algorithm.\n\n***\n\nHere\u2019s how it differs from existing multimodal datasets:\n\n*   **Reasoning Structure:** Unlike many datasets that provide only input-output pairs, **Mulberry-260K** includes explicit, multi-step reasoning paths. These paths are generated through tree search, offering a structured approach to problem-solving. The average reasoning steps is 7.5. The reasoning steps predominantly falls between 6 and 8.\n*   **Diversity of Reasoning Steps:** The dataset contains reasoning paths with flexible numbers of steps, adapting to the complexity of the task. Simpler tasks have fewer steps (averaging 6.8 steps for chart-related subsets), while more complex tasks have more steps (averaging 8.9 steps for geometry-related subsets).\n*   **Reflective Reasoning:** **Mulberry-260K** incorporates reflective reasoning paths, allowing models to learn from both successful and unsuccessful reasoning steps. This is achieved through the **LCoSFT-Re** loss function, which maximizes the log probability of effective and reflective reasoning paths.\n*   **Data Sources:** The raw data is collected from a wide range of domains, including General Multimodal Understanding, Mathematics, Figure Understanding, Real-world Understanding, Science, and Medical Image Understanding.\n*   **Construction Method:** The dataset is constructed using **CoMCTS**, which employs a group of models to search for effective and reflective reasoning paths. This collective approach leverages the strengths of different models to generate high-quality reasoning data."
    },
    {
        "question_id": "2412.18319v2_5",
        "answer": "**Collective Supervised Fine-Tuning (CoSFT)** is a training technique used to enhance the reasoning capabilities of Multimodal Large Language Models (**MLLMs**). It leverages data generated by **Collective Monte Carlo Tree Search (CoMCTS)** to fine-tune these models, specifically improving their ability to perform step-by-step reasoning.\n\n***\n\nHere's a breakdown of how **CoSFT** works and how it uses **CoMCTS**-searched data:\n\n1.  **Data Generation with CoMCTS**:\n    *   **CoMCTS** is employed to search for effective and reflective reasoning paths for a given set of multimodal inputs. This search results in a tree of reasoning nodes, where each node represents an intermediate reasoning step.\n    *   The search process involves multiple **MLLMs** that collectively explore and identify the most promising reasoning paths. This collective approach helps to overcome the limitations of individual models and ensures a diverse set of reasoning trajectories.\n    *   The resulting dataset, like **Mulberry-260K**, contains rich, explicit, and well-defined reasoning nodes for each question.\n\n2.  **Supervised Fine-Tuning**:\n    *   The data generated by **CoMCTS** is then used to fine-tune the **MLLMs** through supervised learning. This involves training the models to predict the next reasoning step in a sequence, given the input question and the previous reasoning steps.\n    *   The **CoSFT** process maximizes the log probability of effective and reflective reasoning paths over the tree of reasoning nodes generated by **CoMCTS**. This encourages the models to learn from both positive and negative examples, improving their ability to calibrate their reasoning trajectory.\n\n3.  **Reflective Reasoning**:\n    *   **CoSFT** is extended for reflective reasoning by integrating negative sibling nodes into effective reasoning paths. This creates reflective reasoning paths that include a transition from a negative reasoning node to a positive one.\n    *   By learning from these reflective reasoning paths, **MLLMs** can perform appropriate step-wise reflection, dynamically calibrating their reasoning trajectory from an erroneous node toward a correct one during long-chain reasoning.\n\nIn summary, **CoSFT** leverages the diverse and high-quality reasoning data generated by **CoMCTS** to fine-tune **MLLMs**, improving their step-by-step reasoning capabilities. The collective approach of **CoMCTS** ensures a rich set of reasoning paths, while the supervised fine-tuning process enables the models to learn from both positive and negative examples, leading to more robust and accurate reasoning."
    },
    {
        "question_id": "2412.18319v2_6",
        "answer": "Okay, I will explain how **CoMCTS** compares to other tree search methods like **ReST-MCTS** and **Omega-MCTS** focusing on **search success rate** and **computational efficiency**.\n\n***\n\n### CoMCTS vs. Other Tree Search Methods\n\nThe paper highlights that existing tree search methods often struggle with **search success rate** and **computational efficiency** when applied to **MLLMs**. Here's a breakdown of how **CoMCTS** addresses these challenges compared to other methods:\n\n1.  **Search Success Rate**:\n\n    *   **Limitations of Traditional Methods**: The paper notes that traditional **MCTS** methods, when applied to **MLLMs**, tend to get trapped in homogeneous, low-quality nodes within the reasoning space of a single **MLLM**. This leads to low **search success rates**.\n    *   **CoMCTS's Approach**: **CoMCTS** addresses this by leveraging collective knowledge from multiple **MLLMs**. It explores reasoning paths not only within the reasoning space of a single **MLLM** but also among those of others. By concatenating reasoning trajectories from multiple **MLLMs**, **CoMCTS** constructs a unified reasoning tree comprising diverse and complementary reasoning nodes. This helps avoid being stuck in low-quality nodes and increases the chances of finding effective reasoning paths.\n\n2.  **Computational Efficiency**:\n\n    *   **Inefficiency of Traditional MCTS**: Traditional **MCTS** methods typically expand and explore only one subsequent reasoning node per search iteration, advancing a single step each time. This demands massive iterations, making them inefficient for computationally intensive **MLLMs**.\n    *   **CoMCTS's Approach**: **CoMCTS** improves **computational efficiency** through a joint simulation and error positioning mechanism. In each search iteration, it can skip multiple intermediate steps and select the last correct step as the next start node. This reduces search time while maintaining search effectiveness. The collective knowledge also aids in recognizing and positioning errors, which is crucial for efficiency.\n\n### Specific Comparison with ReST-MCTS\n\nWhile the paper doesn't provide a direct comparison table or experimental results contrasting **CoMCTS** with **ReST-MCTS** or **Omega-MCTS**, we can infer some differences based on the descriptions of **CoMCTS**:\n\n*   **ReST-MCTS**: **ReST-MCTS** (Reasoning with Self-Training) typically bootstraps an **LLM** itself to build a tree of intermediate thoughts and explore effective reasoning paths. **CoMCTS**, on the other hand, uses multiple **MLLMs** to achieve a more diverse exploration of reasoning paths, potentially leading to a higher **search success rate**.\n*   **Computational Efficiency**: **CoMCTS**'s joint simulation and error positioning, which allows skipping multiple intermediate steps, likely makes it more computationally efficient than **ReST-MCTS**, which may require more iterations to explore the reasoning space.\n\n### Summary\n\n| Feature              | Traditional MCTS & ReST-MCTS                                                                        | CoMCTS                                                                                                                                                                                                                                                                                           |\n| :------------------- | :-------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Search Space**     | Limited to the reasoning space of a single MLLM                                                     | Explores reasoning spaces of multiple MLLMs, creating a diverse and complementary reasoning tree                                                                                                                                                                                                  |\n| **Search Efficiency** | Expands one node per iteration, requiring many iterations                                           | Skips multiple intermediate steps per iteration via joint simulation and error positioning                                                                                                                                                                                                              |\n| **Success Rate**     | Lower, due to getting trapped in homogeneous, low-quality reasoning nodes                           | Higher, due to the diversity of reasoning nodes from multiple MLLMs and the ability to learn from both positive and negative reasoning paths                                                                                                                                                     |\n| **Collective Learning**|Relies on self-training or single model adaptation|Leverages collective knowledge from multiple MLLMs to enhance reasoning-path searching and learning. This approach enables collaborative conjecture, search, and identification of effective reasoning paths, improving both search effectiveness and efficiency.|"
    },
    {
        "question_id": "2412.18319v2_7",
        "answer": "The ablation studies in the paper examine the individual contributions of both effective and reflective reasoning data, as well as the impact of collective knowledge sources within the **CoMCTS** framework. Here's a breakdown of what the ablation studies reveal:\n\n***\n\n### Impact of Effective and Reflective Reasoning Data\n\nThe ablation studies likely investigated the performance of the **Mulberry** models when trained without either the effective reasoning data or the reflective reasoning data.\n\n*   **Without Effective Reasoning Data:** Removing effective reasoning data would likely lead to a decrease in the model's ability to generate correct and coherent reasoning paths. The model might struggle to connect the input question to the final answer through a series of logical steps.\n*   **Without Reflective Reasoning Data:** Removing reflective reasoning data would likely reduce the model's capacity to correct its own errors and learn from mistakes. The model might become more prone to following incorrect reasoning paths without recognizing and rectifying them.\n\n***\n\n### Contributions of Collective Knowledge Sources\n\nThe ablation studies also examined how performance changes when collective knowledge sources are removed.\n\n*   **Without Collective Knowledge Sources:** Ablating collective knowledge would mean the model is trained without the diverse perspectives and reasoning paths generated by multiple models during the **CoMCTS** search. This would likely result in a less robust and less accurate reasoning process, as the model would not benefit from the exploration of a wide range of potential solutions. The model's ability to handle complex or ambiguous questions might also be diminished."
    },
    {
        "question_id": "2412.18319v2_8",
        "answer": "The Mulberry model, trained using data searched by Collective Monte Carlo Tree Search (**CoMCTS**), demonstrates strong performance against state-of-the-art multimodal large language models (**MLLMs**) across a range of benchmarks. Here's a breakdown:\n\n***\n\n### General Performance\n\n*   **Open-Source MLLMs**: Mulberry outperforms most open-source **MLLMs**, indicating its effectiveness in step-by-step reasoning and reflection.\n*   **Closed-Source MLLMs**: It achieves competitive results against closed-source models, showcasing its ability to perform at a high level compared to proprietary models.\n\n***\n\n### Specific Benchmark Results\n\nThe evaluation was conducted on eight widely used datasets, covering areas from general and mathematical reasoning to hallucination, visual illusion, and multi-disciplinary understanding. Specific performance metrics include:\n\n*   **MathVista**: Mulberry-LLaVA-8B achieves 56.3, and Mulberry-Llama-11B achieves 61.1.\n*   **MMStar**: Mulberry-LLaVA-8B achieves 54.5, and Mulberry-Llama-11B achieves 58.5.\n*   **MMMU**: Mulberry-LLaVA-8B achieves 43.0, and Mulberry-Llama-11B achieves 45.6.\n*   **ChartQA**: Mulberry-LLaVA-8B achieves 79.5, and Mulberry-Llama-11B achieves 83.5.\n*   **DynaMath**: Mulberry-LLaVA-8B achieves 34.1, and Mulberry-Llama-11B achieves 37.2.\n*   **MM-Math**: Mulberry-LLaVA-8B achieves 47.5, and Mulberry-Llama-11B achieves 48.9.\n*   **MMEsum**: Mulberry-LLaVA-8B achieves 18.9, and Mulberry-Llama-11B achieves 18.7.\n*   **Average Score**: Mulberry-LLaVA-8B achieves 50.7, and Mulberry-Llama-11B achieves 53.3.\n\n***\n\n### Comparison with Reasoning-Response Models\n\n*   **LLaVA-NeXT-8B**: Using the same base model, LLaVA-NeXT-8B, Mulberry outperforms LLaVA-Reasoner-8B and Insight-V-8B on the MathVista benchmark by +5.7% and +6.5%, respectively. On the multi-disciplinary benchmark MMMU, the gains are +3.0% and +1.0%, respectively.\n*   **LLaVA-COT-11B**: Mulberry-11B surpasses LLaVA-COT-11B by +6.3% on the reasoning-intensive benchmark MathVista under the same baseline LLaMA-3.2-11B-Vision-Instruct.\n\nThese results indicate that **CoMCTS** significantly enhances the reasoning capabilities of the Mulberry model, allowing it to perform competitively against both open-source and closed-source **MLLMs**."
    },
    {
        "question_id": "2412.18319v2_9",
        "answer": "Here's an overview of the potential applications of **Mulberry-260K** and **CoMCTS**, along with the remaining open challenges in multimodal reasoning:\n\n***\n\n### Potential Applications of Mulberry-260K and CoMCTS\n\n*   **Enhanced Multimodal Understanding**:\n    *   **Reasoning Flexibility**: **CoMCTS** enables the generation of effective reasoning trajectories with flexible numbers of reasoning steps. This allows models to \"think less and faster\" when handling simple questions and \"think more and slower\" when tackling complex tasks, making **MLLMs** more adaptive in real-world scenarios.\n*   **Training Data for Reasoning-Based MLLMs**:\n    *   **Explicit Reasoning Steps**: **Mulberry-260K** provides a valuable resource for advancing research in step-by-step reasoning and reflection in **MLLMs**. By training on a dataset with rich, explicit, and well-defined reasoning nodes, **MLLMs** can learn to create each intermediate step of the reasoning involved until the final answer.\n\n***\n\n### Open Challenges in Multimodal Reasoning\n\n*   **Search Effectiveness**:\n    *   Current **MLLMs** are typically trained with few explicit and well-defined intermediate reasoning steps, making search methods often trapped in homogeneous low-quality nodes within the reasoning space of a single **MLLM**, ultimately leading to low search success rates.\n*   **Search Efficiency**:\n    *   Traditional **MCTS** methods typically expand and explore only one subsequent reasoning node per search iteration, which advances a single step each time and demands massive iterations, making them inefficient for computation-intensive **MLLMs**."
    }
]