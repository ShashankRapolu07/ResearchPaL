[
    {
        "question_id": "2412.18319v2_0",
        "answer": "The paper identifies key shortcomings of current **Multimodal Large Language Models (MLLMs)** when dealing with complex tasks.\n\n***\n\n### Key Failures of Current MLLMs\n\n*   **Limited Reasoning Depth**: Existing MLLMs often struggle with tasks requiring in-depth reasoning. They tend to operate in a \"direct prediction\" mode, providing brief answers without explicit intermediate reasoning steps. This is because they are often trained without rich, well-defined reasoning processes.\n*   **Search Effectiveness**: Applying traditional tree search methods directly to MLLMs doesn't work well because MLLMs are typically trained with limited explicit reasoning steps. This leads to the search being trapped in low-quality reasoning nodes, reducing the chances of finding successful reasoning paths.\n*   **Search Efficiency**: Traditional **Monte Carlo Tree Search (MCTS)** methods explore only one subsequent reasoning node per iteration, which is inefficient for computationally intensive MLLMs.\n\n***\n\n### Proposed Approach: Collective Monte Carlo Tree Search (CoMCTS)\n\nTo address these challenges, the paper introduces **Collective Monte Carlo Tree Search (CoMCTS)**, a novel method designed to enhance the reasoning capabilities of MLLMs.\n\n*   **Collective Knowledge**: **CoMCTS** leverages collective knowledge from multiple models to collaboratively search for effective reasoning paths. This helps to overcome the limitations of individual models and promotes more diverse and comprehensive exploration of the reasoning space.\n*   **Iterative Operations**: **CoMCTS** iteratively searches for reasoning paths using four key operations:\n    *   **Expansion**: Jointly expands diverse candidate reasoning nodes using multiple MLLMs.\n    *   **Simulation and Error Positioning**: Simulates reasoning outcomes, identifies error nodes, and prunes them.\n    *   **Backpropagation**: Updates the score and visit count of each reasoning node.\n    *   **Selection**: Selects the next start node based on the Upper Confidence Bound value.\n*   **Reflective Reasoning**: The approach extends **CoMCTS** for reflective reasoning-path search. It integrates negative sibling nodes into effective reasoning paths, allowing MLLMs to learn from errors and calibrate their reasoning trajectory.\n\nBy using **CoMCTS**, the authors constructed **Mulberry-260k**, a multimodal dataset with a tree of reasoning nodes for each question. They then trained the **Mulberry** model using collective supervised fine-tuning, resulting in MLLMs with enhanced step-by-step reasoning and reflection capabilities."
    },
    {
        "question_id": "2412.18319v2_1",
        "answer": "**Collective Monte Carlo Tree Search (CoMCTS)**\n\nCoMCTS is a novel learning-to-reason method designed for Multimodal Large Language Models (MLLMs). It enhances the traditional \"tree search\" approach by incorporating the concept of collective learning. The primary objective of CoMCTS is to utilize collective knowledge from multiple models to collaboratively identify effective reasoning paths that lead to correct answers.\n\n***\n\n**Key Differences Between CoMCTS and Traditional MCTS**\n\nHere's a breakdown of the key differences between CoMCTS and traditional MCTS in the context of reasoning path search:\n\n1.  **Search Effectiveness:**\n\n    *   Traditional MCTS relies on self-bootstrapping, which can be limiting for MLLMs that haven't been trained with explicit intermediate reasoning steps. This often leads to the search getting stuck in homogeneous, low-quality nodes, resulting in low success rates.\n    *   CoMCTS addresses this by leveraging collective knowledge from multiple MLLMs. It constructs a unified reasoning tree comprising diverse and complementary reasoning nodes. This allows the search to explore reasoning paths not only within a single MLLM's reasoning space but also across multiple models, benefiting from their combined strengths.\n\n2.  **Search Efficiency:**\n\n    *   Traditional MCTS methods typically expand and explore only one subsequent reasoning node per search iteration, advancing a single step at a time. This requires massive iterations, making it inefficient for computation-intensive MLLMs.\n    *   CoMCTS improves efficiency through a joint simulation and error positioning mechanism. In each search iteration, it can skip multiple intermediate steps and select the last correct step as the next starting node. This significantly reduces search time while maintaining effectiveness.\n\n3.  **Error Positioning:**\n\n    *   CoMCTS employs an error positioning mechanism that enables it to skip multiple intermediate steps in each search iteration. This mechanism selects the last correct step as the next start node, which largely reduces search time while maintaining search effectiveness.\n    *   Collective knowledge is crucial here because it is often easier for a model to recognize errors made by other models than by itself.\n\n4.  **Reflective Reasoning:**\n\n    *   CoMCTS extends its functionality to reflective reasoning-path search. By integrating negative sibling nodes into effective reasoning paths, it builds reflective reasoning paths that include a transition from a negative to a positive reasoning node.\n    *   This allows MLLMs to learn from both positive and negative examples, dynamically adjusting their reasoning trajectory from erroneous nodes toward correct ones during long-chain reasoning.\n\n5.  **Core Operations:**\n\n    *   CoMCTS searches effective reasoning paths iteratively, and in each iteration, it leverages collective knowledge from multiple MLLMs to jointly:\n        *   Expand diverse and complementary candidate subsequent reasoning nodes till the end from a given start node.\n        *   Simulate reasoning outcomes, position error candidate nodes, and prune them along with their child nodes.\n        *   Backpropagate to update the score and visit count of each reasoning node in a bottom-up manner.\n        *   Select the leaf reasoning node with the highest **Upper Confidence Bound (UCB)** value as the next start node.\n\n***"
    },
    {
        "question_id": "2412.18319v2_2",
        "answer": "The paper introduces Collective Monte Carlo Tree Search (**CoMCTS**) as a novel approach to enhance reasoning in Multimodal Large Language Models (**MLLMs**). **CoMCTS** leverages collective knowledge from multiple models through four key iterative operations:\n\n***\n\n### 1. Expansion\n\n*   **Goal**: To broaden the search space by generating new, diverse reasoning paths from a given node.\n*   **Process**:\n    *   Given a current leaf node, **CoMCTS** uses a group of **MLLMs** ($\\{\u03c01, \u03c02, ..., \u03c0K\\}$) to expand candidate reasoning paths in parallel.\n    *   Each model $\u03c0j$ generates a potential reasoning path $Sj candidate$ based on the current node $sk m$, its parent nodes $Parent(sk m)$, and the question $Q$.\n    *   Equation: $Sj candidate \u223c\u03c0j(\u00b7|Q, Parent(sk m), sk m)$\n*   **Improvement to Reasoning**: By using multiple **MLLMs**, **CoMCTS** explores a more diverse set of reasoning paths, avoiding the limitations of a single model's reasoning space. This leads to a more comprehensive and effective search for correct reasoning.\n\n***\n\n### 2. Simulation and Error Positioning\n\n*   **Goal**: To evaluate the potential value of newly added reasoning nodes and filter out erroneous ones.\n*   **Process**:\n    *   **CoMCTS** uses collective knowledge from $\\{\u03c01, \u03c02, ..., \u03c0K\\}$ to estimate the value of child nodes $sj i$ in $Scandidate$.\n    *   A reasoning node evaluation function $R(sj i)$ assigns scores to each node based on the evaluations from multiple **MLLMs**.\n    *   Low-score nodes are considered erroneous and are removed along with their child nodes using a threshold $t$.\n    *   Equations:\n        *   $R(sj i) = \frac{1}{K} \\sum{l=1}^{K} \u03c0l(\u00b7|prompteval, Q, Parent(sj i), sj i)$\n        *   $S\u2217 candidate = \\{sj i \u2208Scandidate|R(sj i) >= t\\}$\n*   **Improvement to Reasoning**: This operation enhances reasoning efficiency by pruning unpromising paths early on. The error positioning mechanism allows **CoMCTS** to skip intermediate steps and focus on more promising paths, reducing search time while maintaining effectiveness.\n\n***\n\n### 3. Backpropagation\n\n*   **Goal**: To update the value and visit count of nodes in the reasoning tree based on the simulation results.\n*   **Process**:\n    *   After expansion and simulation, **CoMCTS** updates the statistics of each node $s$ along the newly expanded path in a bottom-up manner.\n    *   The visit count $N(s)$ and node value $V(s)$ are updated based on the rewards of child nodes.\n    *   Equations:\n        *   $V(s) \u2190 \frac{N(s) \u22c5 V(s) + \\sum{sl\u2208Child(s)} R(sl)}{N(s) + CountChild(S\u2217 candidate, s)}$\n        *   $N(s) \u2190 N(s) + CountChild(S\u2217 candidate, s)$\n*   **Improvement to Reasoning**: Backpropagation ensures that the reasoning tree reflects the outcomes of the simulation, guiding the search towards more promising paths. By updating node values and visit counts, **CoMCTS** refines its understanding of the reasoning space.\n\n***\n\n### 4. Selection\n\n*   **Goal**: To choose the most promising node to expand in the next iteration.\n*   **Process**:\n    *   **CoMCTS** traverses the updated reasoning tree to select the next starting node.\n    *   The selection is guided by the Upper Confidence Bound (**UCB**) value, which balances exploration and exploitation.\n    *   The node with the highest **UCB** value is chosen as the starting node $sk\u2217 m$ for the next search iteration.\n    *   Equation: $sk\u2217 m = arg max{s\u2208S\u2217 candidate} V (s) + c \u22c5 \\sqrt{\frac{log N(\\hat{s})}{1 + N(s)}}$\n*   **Improvement to Reasoning**: The selection process ensures that **CoMCTS** balances the exploration of new paths with the exploitation of known promising paths. This leads to a more efficient and effective search for the correct reasoning path.\n\n***\n\nIn summary, these four operations enable **CoMCTS** to effectively explore the reasoning space, identify and prune erroneous paths, and focus on promising paths, leading to improved reasoning efficiency and effectiveness in **MLLMs**."
    },
    {
        "question_id": "2412.18319v2_3",
        "answer": "CoMCTS (Collective Monte Carlo Tree Search) enhances reflective reasoning in Multimodal Large Language Models (MLLMs) by strategically incorporating negative sibling nodes into the reasoning process. Here's a breakdown:\n\n### Identifying Negative Sibling Nodes\n\n*   For each step in an effective reasoning path, CoMCTS identifies related but incorrect reasoning steps, referred to as \"negative sibling nodes.\"\n*   This identification leverages the Upper Confidence Bound (UCB) values, which quantify the balance between exploration and exploitation in the tree search.\n\n### Constructing Reflective Reasoning Paths\n\n*   CoMCTS samples a reasoning step from the original, effective path and its corresponding negative sibling node.\n*   These are then combined with a \"reflection prompt\" (e.g., \"The previous reasoning step is wrong and let's rethink it again.\"). This creates a reflective trajectory: (negative sibling node, reflection prompt, original node).\n*   This trajectory replaces the original step in the path, forming a reflective reasoning path.\n\n### Training with Reflective Reasoning\n\n*   The MLLM is trained using these reflective reasoning paths. This training aims to teach the model to:\n\n    *   Recognize erroneous reasoning steps.\n    *   Calibrate its reasoning trajectory by transitioning from incorrect nodes to correct ones.\n\n### Benefits for MLLMs\n\n*   **Error Correction:** By explicitly exposing the model to incorrect reasoning steps and prompting it to rethink, CoMCTS enables MLLMs to learn from their mistakes.\n\n*   **Robustness:** Reflective reasoning enhances the model's ability to handle noisy or ambiguous inputs by encouraging it to critically evaluate its own reasoning process.\n\n*   **Improved Reasoning:** The model learns to dynamically adjust its reasoning trajectory, leading to more accurate and reliable results in complex multimodal tasks.\n\n***"
    },
    {
        "question_id": "2412.18319v2_4",
        "answer": "**Mulberry-260K** is a multimodal learning-to-reason-and-reflect dataset created by the authors. It comprises 260,000 raw multimodal input questions gathered from various domains.\n\n***\n\nHere's a breakdown of its key aspects:\n\n*   **Construction:** The dataset is built using a Collective Monte Carlo Tree Search (**CoMCTS**) approach to find effective and reflective reasoning paths for multimodal questions.\n*   **Reasoning Structure:** Unlike many datasets that provide only input-output pairs, **Mulberry-260K** includes a tree of rich, explicit, and well-defined reasoning nodes for each question. These nodes represent intermediate steps toward the final answer, enabling models to learn step-by-step reasoning.\n*   **Reflective Reasoning:** The dataset incorporates reflective reasoning paths, which include transitions from negative reasoning nodes to positive ones. This allows models to learn from mistakes and refine their reasoning process.\n*   **Diversity:** The dataset covers a wide range of domains, including:\n\n    *   Mathematics\n    *   Figure Understanding\n    *   Math Word Problems\n    *   Medical Data\n    *   Science\n    *   Nature World QA\n\n    This broad coverage ensures that models trained on **Mulberry-260K** can generalize to various types of reasoning tasks."
    },
    {
        "question_id": "2412.18319v2_5",
        "answer": "**Collective Supervised Fine-Tuning (CoSFT)** is a training technique used to enhance the reasoning capabilities of Multimodal Large Language Models (MLLMs). It leverages data generated through Collective Monte Carlo Tree Search (**CoMCTS**) to refine the models' ability to perform step-by-step reasoning and reflection.\n\nHere's a breakdown of how **CoSFT** works with **CoMCTS**-searched data:\n\n1.  **Data Generation with CoMCTS:**\n    *   **CoMCTS** is employed to explore and construct reasoning paths for a given set of multimodal inputs (e.g., questions with images).\n    *   This search process results in a tree-like structure of reasoning nodes, where each node represents an intermediate step in the reasoning process.\n    *   The tree contains both correct and incorrect reasoning steps, allowing the model to learn from both positive and negative examples.\n2.  **Dataset Construction:**\n    *   The reasoning trees generated by **CoMCTS** are used to create a dataset (**Mulberry-260k**).\n    *   Each entry in the dataset consists of a question, a correct reasoning path, and the broader tree of explored reasoning steps.\n    *   This dataset provides rich, explicit, and well-defined reasoning nodes for each question.\n3.  **Supervised Fine-Tuning:**\n    *   The MLLMs are then trained using supervised fine-tuning (SFT) on the **CoMCTS**-generated dataset.\n    *   The models learn to predict the next correct step in the reasoning process, given the input question and the preceding steps.\n    *   By training on the diverse set of reasoning paths explored by **CoMCTS**, the models improve their ability to generate coherent and accurate reasoning chains.\n4.  **Collective Learning:**\n    *   **CoSFT** incorporates a collective learning approach, where multiple models collaborate to improve the overall learning outcome.\n    *   This can involve training multiple models on the same dataset and then combining their knowledge through techniques like ensembling or knowledge distillation.\n    *   The collective aspect helps to overcome limitations of individual models and promotes more robust and generalizable reasoning abilities.\n\nIn summary, **CoSFT** leverages the structured reasoning data generated by **CoMCTS** to train MLLMs to perform step-by-step reasoning. By learning from both correct and incorrect reasoning paths, and by incorporating collective knowledge from multiple models, **CoSFT** enables MLLMs to dynamically calibrate their reasoning trajectory, moving from erroneous nodes toward correct ones during long-chain reasoning."
    },
    {
        "question_id": "2412.18319v2_6",
        "answer": "Here's a breakdown of how **CoMCTS** compares to other tree search methods like **ReST-MCTS** and **Omega-MCTS**, focusing on **search success rate** and **computational efficiency**.\n\n***\n\n### Search Success Rate\n\n*   **CoMCTS**: Achieves a significantly higher search success rate compared to traditional **MCTS**, **ReST-MCTS**, and **Omega-MCTS**. This indicates that **CoMCTS** is more effective at finding correct reasoning paths. The collective approach allows it to explore a more diverse set of reasoning nodes, avoiding the pitfalls of getting stuck in low-quality reasoning spaces that can plague single-model-based methods.\n\n*   **ReST-MCTS**: Shows some improvement over basic **MCTS** by introducing partial search enhancements.\n\n*   **Omega-MCTS**: Improves upon basic **MCTS** by using binary search to make the process more efficient.\n\n*   **Traditional MCTS**: Improvement over direct prediction is limited, often getting stuck in homogenous, low-quality reasoning nodes.\n\n***\n\n### Computational Efficiency\n\n*   **CoMCTS**: Demonstrates greater computational efficiency, requiring fewer search iterations to achieve successful reasoning paths. The joint simulation and error positioning mechanisms enable **CoMCTS** to skip multiple intermediate steps, significantly reducing search time.\n\n*   **ReST-MCTS**: Is more computationally efficient than traditional **MCTS**, as it enhances **MCTS** by introducing partial search.\n\n*   **Omega-MCTS**: Is more computationally efficient than traditional **MCTS**, as it improves **MCTS** by designing binary search.\n\n*   **Traditional MCTS**: Requires more iterations, making it less efficient for computation-intensive **MLLM**s.\n\n***\n\n### Summary Table\n\n| Method          | Search Success Rate | Computational Efficiency (Avg. Search Iterations) |\n| :-------------- | :------------------ | :------------------------------------------------ |\n| **CoMCTS**      | Highest             | Highest                                           |\n| Omega-MCTS      | High                | High                                              |\n| ReST-MCTS       | Medium              | Medium                                            |\n| Traditional MCTS| Low                 | Low                                               |"
    },
    {
        "question_id": "2412.18319v2_7",
        "answer": "The ablation studies in the paper \"Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\" provide insights into the contribution of different components of the proposed Collective Monte Carlo Tree Search (CoMCTS) framework. Let's break down what the ablation studies revealed:\n\n***\n\n### Impact of Removing Collective Learning\n\nThe ablation studies investigated the effect of removing collective knowledge during the MCTS process. The key finding here would be how performance changes when the models don't have access to the diverse perspectives offered by the ensemble of MLLMs. Without collective learning, the search for effective reasoning paths relies solely on the individual model's capabilities, potentially leading to:\n\n*   Reduced exploration of the reasoning space.\n*   Suboptimal reasoning paths due to the lack of diverse viewpoints for error correction and refinement.\n*   Decreased robustness in handling noisy or ambiguous multimodal inputs.\n\n***\n\n### Impact of Removing Reflective Reasoning Data\n\nThe ablation studies also examined the impact of reflective reasoning data. Reflective reasoning involves explicitly teaching the model to identify and correct its errors by incorporating negative reasoning nodes into the training data. Removing reflective reasoning data would likely result in:\n\n*   A decreased ability of the model to recover from incorrect reasoning steps.\n*   A higher likelihood of the model getting stuck in erroneous reasoning paths.\n*   Reduced calibration of the model, making it less sensitive to the correctness of its intermediate reasoning steps.\n\n***\n\nIn summary, the ablation studies likely demonstrated that both collective learning and reflective reasoning are crucial components of CoMCTS. Removing either of these components would lead to a degradation in the model's reasoning and reflection capabilities, highlighting the importance of leveraging collective knowledge and learning from mistakes for effective multimodal reasoning."
    },
    {
        "question_id": "2412.18319v2_8",
        "answer": "The **Mulberry** model, trained using data searched by **Collective Monte Carlo Tree Search (CoMCTS)**, demonstrates strong performance when compared to state-of-the-art multimodal large language models (**MLLMs**) across several benchmarks. Here's a breakdown:\n\n***\n\n### General Performance\n\n*   **Outperforms Open-Source MLLMs**: **Mulberry** generally surpasses most open-source **MLLMs**, indicating its effectiveness in leveraging the **CoMCTS**-searched data for improved reasoning and understanding.\n*   **Competitive with Closed-Source Models**: It achieves results that are competitive with those of closed-source **MLLMs**, suggesting that the approach is capable of reaching near state-of-the-art capabilities.\n\n***\n\n### Specific Benchmarks\n\nThe evaluation covers a range of tasks, including general reasoning, mathematical reasoning, hallucination detection, visual illusion understanding, and multi-disciplinary reasoning.\n\n*   **MathVista**: On the **MathVista** benchmark, **Mulberry** shows significant gains over other models. For example, when using the same base model (**LLaVA-NeXT-8B**), **Mulberry** outperforms **LLaVA-Reasoner-8B** and **Insight-V-8B** by considerable margins.\n*   **MMMU**: In the multi-disciplinary benchmark **MMMU**, **Mulberry** also demonstrates superior performance compared to other models with the same base architecture.\n*   **Reasoning-Intensive Tasks**: **Mulberry-11B** surpasses **LLaVA-COT-11B** on reasoning-intensive benchmarks like **MathVista**, indicating the effectiveness of **CoMCTS** in generating explicit reasoning steps.\n\n***\n\n### Improvements Over Baselines\n\n*   **Models Involved in Collective Learning**: When **Mulberry** models are trained on jointly-searched data (i.e., **Mulberry-260K**), they show clear performance improvements compared to their baselines (e.g., **Qwen2-VL-7B** and **LLaMA-3.2-11B-Vision-Instruct**).\n*   **Models Not Involved in Collective Learning**: Even when applied to models not involved in the **CoMCTS** process (e.g., **Qwen2-VL-2B** and **LLaVA-NeXT-8B**), training with **Mulberry-260K** enhances their performance, demonstrating the generalization capability of the searched data.\n\n***\n\n### Key Takeaways\n\n*   **Effective Reasoning**: The gains are largely attributed to **CoMCTS**, which facilitates tree search and provides rich, explicit, and well-defined reasoning nodes with flexible numbers of steps.\n*   **Step-by-Step Reasoning and Reflection**: **Mulberry** exhibits outstanding abilities in step-by-step reasoning and reflection, which are crucial for complex problem-solving.\n*   **Search Effectiveness and Efficiency**: **CoMCTS** improves both the effectiveness and efficiency of the search process, leading to better reasoning paths and, consequently, better model performance."
    },
    {
        "question_id": "2412.18319v2_9",
        "answer": "Here's an analysis of the potential applications of the **Mulberry-260K** dataset and **CoMCTS** (Collective Monte Carlo Tree Search) method, along with remaining challenges in multimodal reasoning:\n\n***\n\n### Potential Applications of Mulberry-260K and CoMCTS\n\n*   **Enhanced Multimodal Reasoning in AI Assistants:**\n\n    *   Enables AI assistants to handle complex queries that require integrating visual and textual information.\n    *   Improves step-by-step reasoning, allowing assistants to explain their thought processes and provide more transparent and trustworthy answers.\n\n*   **Improved Performance in Educational Tools:**\n\n    *   Facilitates the development of intelligent tutoring systems that can understand and respond to student questions involving diagrams, charts, and other visual aids.\n    *   Supports the creation of tools that can provide detailed, step-by-step solutions for complex problems in subjects like mathematics and science.\n\n*   **Advancements in Medical Image Analysis:**\n\n    *   Aids in the development of AI systems that can analyze medical images (e.g., X-rays, MRIs) and provide diagnostic support to medical professionals.\n    *   Facilitates the creation of tools that can explain the reasoning behind their diagnoses, increasing trust and acceptance among healthcare providers.\n\n*   **Robotics and Autonomous Systems:**\n\n    *   Enables robots to better understand and interact with their environment by integrating visual and textual cues.\n    *   Supports the development of robots that can perform complex tasks requiring reasoning about objects, scenes, and instructions.\n\n*   **Creative Content Generation:**\n\n    *   Facilitates the creation of AI tools that can generate creative content (e.g., image captions, stories) based on multimodal inputs.\n    *   Supports the development of systems that can reason about the relationships between visual and textual elements, leading to more coherent and engaging content.\n\n***\n\n### Remaining Open Challenges in Multimodal Reasoning\n\n*   **Handling Compositionality and Structural Complexity:**\n\n    *   Many real-world tasks require understanding the compositional structure of both visual scenes and textual descriptions.\n    *   Developing models that can effectively parse and reason about complex, structured information remains a challenge.\n\n*   **Reasoning with Incomplete or Noisy Data:**\n\n    *   Real-world data is often incomplete, ambiguous, or contains noise.\n    *   Creating models that can robustly reason under such conditions is an ongoing area of research.\n\n*   **Commonsense Reasoning and Background Knowledge:**\n\n    *   Effective multimodal reasoning often requires incorporating commonsense knowledge and background information.\n    *   Integrating external knowledge sources and reasoning mechanisms into MLLMs remains a significant challenge.\n\n*   **Causal Reasoning:**\n\n    *   Many real-world tasks require understanding causal relationships between events and entities.\n    *   Developing models that can infer causal relationships from multimodal data is a difficult but important area of research.\n\n*   **Explainability and Interpretability:**\n\n    *   As MLLMs become more complex, it is increasingly important to understand how they arrive at their conclusions.\n    *   Developing methods for explaining and interpreting the reasoning processes of MLLMs is crucial for building trust and ensuring responsible use.\n\n*   **Generalization and Robustness:**\n\n    *   MLLMs often struggle to generalize to new domains or tasks that differ significantly from their training data.\n    *   Improving the generalization and robustness of MLLMs is essential for deploying them in real-world applications."
    }
]