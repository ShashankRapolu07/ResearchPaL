[
    {
        "question_id": "2412.18319v2_rqe_0",
        "answer": "# Summary of \"Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search\"\n\n## **1. Introduction**\nThe paper introduces **Mulberry**, a multimodal large language model (**MLLM**) that is capable of **step-by-step reasoning and reflection**. The authors propose **Collective Monte Carlo Tree Search (CoMCTS)**, a novel learning-to-reason method that integrates **collective learning** into tree search to improve reasoning efficiency and effectiveness.\n\nCurrent **MLLMs** often struggle with complex reasoning tasks due to their reliance on **direct prediction**, where they generate final answers without explicitly modeling intermediate reasoning steps. Inspired by **AlphaGo\u2019s tree search** methods, the authors develop **CoMCTS** to collectively explore and refine reasoning paths using multiple MLLMs.\n\n---\n\n## **2. Challenges in Traditional MCTS for MLLMs**\nApplying traditional **Monte Carlo Tree Search (MCTS)** directly to MLLMs faces two major challenges:\n\n1. **Search Effectiveness**:  \n   - Traditional MCTS relies on self-bootstrapping, but MLLMs typically lack **explicit, well-defined** intermediate reasoning steps.  \n   - This leads to models getting stuck in **low-quality reasoning nodes**, lowering search success rates.\n\n2. **Search Efficiency**:  \n   - Conventional MCTS expands and explores **one reasoning node per iteration**, which is **computationally expensive** for large-scale MLLMs.\n\n---\n\n## **3. Proposed Approach: CoMCTS**\nTo address these challenges, **CoMCTS** leverages **collective knowledge** from multiple MLLMs to collaboratively:\n- Conjecture\n- Search\n- Identify **effective reasoning paths**\n\n### **3.1 Key Components of CoMCTS**\nEach iteration of **CoMCTS** consists of four key operations:\n\n1. **Expansion**  \n   - Uses multiple MLLMs to generate **diverse and complementary** reasoning nodes.  \n   - This prevents models from getting stuck in **homogeneous low-quality nodes**.\n\n2. **Simulation and Error Positioning**  \n   - Estimates the correctness of generated reasoning paths by leveraging multiple MLLMs.  \n   - Prunes incorrect reasoning paths **before they propagate errors further**.\n\n3. **Backpropagation**  \n   - Updates reasoning node scores and visit counts from **leaf nodes back to the root**.\n\n4. **Selection**  \n   - Chooses the **next reasoning node** based on an **Upper Confidence Bound (UCB)** strategy, balancing exploration and exploitation.\n\n---\n\n### **3.2 Reflective Reasoning with CoMCTS**\n- Beyond **effective reasoning**, the authors introduce **reflective reasoning** using **negative sibling nodes**.\n- **Reflective paths** incorporate a transition from an **incorrect** reasoning step to a **corrected** one, enabling MLLMs to self-correct dynamically.\n\n---\n\n## **4. Dataset: Mulberry-260k**\nUsing **CoMCTS**, the authors construct **Mulberry-260k**, a **large-scale multimodal dataset** containing:\n- **260,000 multimodal questions** (text + images)\n- **Detailed reasoning trees** with explicit intermediate steps\n- **Reflective reasoning paths** for model self-correction\n\nThe dataset covers **various domains**, including:\n- General multimodal understanding\n- Mathematics\n- Real-world understanding\n- Science\n- Medical image understanding\n\n---\n\n## **5. Model Training: Mulberry MLLMs**\n- The **Mulberry** model family is trained using **collective supervised fine-tuning (CoSFT)**.\n- The loss function optimizes both **effective and reflective reasoning paths**.\n- Training involves a mix of **large (GPT-4o, Qwen2-VL-72B) and smaller (Qwen2-VL-7B, LLaMA-3.2-11B) models**, ensuring **diverse knowledge sources**.\n\n---\n\n## **6. Experiments & Results**\n### **6.1 Main Benchmark Comparisons**\nThe **Mulberry models** are evaluated across **8 challenging reasoning benchmarks**, including:\n- **MathVista** (Mathematical reasoning)\n- **MMMU** (Multidisciplinary reasoning)\n- **ChartQA** (Visual understanding)\n- **HallBench** (Hallucination detection)\n\n**Key results:**\n- **Mulberry-7B** outperforms **Qwen2-VL-7B** by **+4.2%**\n- **Mulberry-11B** surpasses **LLaMA-3.2-11B** by **+7.5%**\n- Mulberry models outperform most **open-source MLLMs** and achieve competitive performance with **closed-source models (GPT-4o, Claude-3.5 Sonnet)**.\n\n---\n\n### **6.2 Comparison with Other Tree Search Methods**\nThe authors compare **CoMCTS** against:\n- **MCTS (Standard Monte Carlo Tree Search)**\n- **ReST-MCTS (Partial search)**\n- **Omega-MCTS (Binary search)**\n\nResults show **CoMCTS achieves:**\n- **80.2% search success rate** (vs. 63.8% for MCTS)\n- **12.7 average search iterations** (vs. 42.1 for MCTS), demonstrating **superior efficiency**.\n\n---\n\n### **6.3 Ablation Studies**\n#### **Impact of Reflective Reasoning**\n- Adding **reflective reasoning paths** improves accuracy by **+0.8%**.\n- **Negative sibling nodes** help models **self-correct reasoning errors**.\n\n#### **Effectiveness of Collective Learning**\n- Including **more models** in CoMCTS consistently improves performance.\n- Even small models like **Qwen2-VL-7B** contribute to the final reasoning tree.\n\n---\n\n## **7. Discussion**\n### **Key Advantages of CoMCTS**\n1. **Better Reasoning Accuracy**\n   - **Explicit intermediate steps** ensure reliable reasoning.\n   - **Collective learning** mitigates single-model biases.\n\n2. **Higher Efficiency**\n   - **Faster tree search** than traditional MCTS.\n   - **Reduces redundant computations**.\n\n3. **Reflective Learning**\n   - Models learn to **identify and correct** their own mistakes.\n   - Improves **long-chain reasoning capabilities**.\n\n---\n\n## **8. Conclusion**\n- **CoMCTS** is a **new learning-to-reason approach** that introduces **collective learning** into **tree search**.\n- The **Mulberry-260k** dataset provides **rich reasoning trees** for MLLMs.\n- The **Mulberry model family** achieves **state-of-the-art** results across multiple reasoning benchmarks.\n- This work **paves the way** for future research in **MLLM reasoning and reflection**.\n\n---\n\n## **9. Code & Resources**\nThe code for **Mulberry** and **CoMCTS** will be available at:  \n[\ud83d\udd17 GitHub Repository](https://github.com/HJYao00/Mulberry)\n\n---\n"
    },
    {
        "queston_id": "2412.18319v2_rqe_1",
        "answer": "# Mulberry-260K Dataset: Construction, Observations, and Model Performance Impact\n\n## **How is the Mulberry-260K dataset constructed?**\n\nMulberry-260K is a **multimodal dataset** designed to enhance reasoning and reflection capabilities in Multimodal Large Language Models (MLLMs). It is constructed using **Collective Monte Carlo Tree Search (CoMCTS)**, a novel learning-to-reason method that employs a collective learning paradigm in tree search.\n\n### **Key steps in constructing Mulberry-260K:**\n1. **Data Collection:**  \n   - The dataset includes **260K multimodal input questions**, each consisting of text and images.  \n   - Sources cover various domains, including **General Multimodal Understanding, Mathematics, Figure Understanding, Real-world Understanding, Science, and Medical Image Understanding**.\n\n2. **Reasoning Path Search with CoMCTS:**  \n   - CoMCTS iteratively searches for **effective and reflective reasoning paths** using multiple MLLMs collaboratively.  \n   - The process includes:\n     - **Expansion:** Generating diverse reasoning steps from different models.\n     - **Simulation and Error Positioning:** Evaluating generated steps and pruning incorrect paths.\n     - **Backpropagation:** Updating reasoning scores and visit counts.\n     - **Selection:** Choosing the most promising reasoning node for the next step.\n   - This results in a **tree of rich, explicit, and well-defined reasoning nodes** for each question.\n\n3. **Incorporation of Reflective Reasoning:**  \n   - **Reflective reasoning paths** are constructed by identifying **negative sibling nodes** and integrating them into the reasoning trajectory.  \n   - This allows models to learn **error correction and step-wise reflection**.\n\n4. **Final Dataset Composition:**  \n   - The dataset comprises **260K questions with detailed reasoning trees**.  \n   - **15K samples** are explicitly used for **reflective reasoning training** to avoid excessive reflection-focused data.\n\n---\n\n## **What multimodal sources contribute to Mulberry-260K?**\nMulberry-260K sources data from a diverse range of multimodal tasks, ensuring broad generalization and robustness. Key sources include:\n- **Mathematics & Logical Reasoning:** Geometric problem-solving, algebraic reasoning, and figure-based problem interpretation.\n- **Real-world Understanding:** Questions involving real-world scenarios requiring both **visual perception** and **language reasoning**.\n- **Science & Medical Image Understanding:** Tasks related to physics, chemistry, biology, and **radiology-based question answering**.\n- **Chart and Diagram Interpretation:** Understanding **infographics, data visualizations, and structural images**.\n- **Hallucination and Visual Illusion Challenges:** Testing models on tricky **perception and reasoning** tasks.\n\nThese sources help build **diverse and structured reasoning paths**, enabling MLLMs to develop **step-by-step reasoning skills**.\n\n---\n\n## **Key Observations from the Distribution of Reasoning Steps in Mulberry-260K**\n\n### **1. Overall Reasoning Step Distribution**\n- Most **reasoning paths** in Mulberry-260K contain **6 to 8 reasoning steps**, with an **average of 7.5 steps per question**.\n\n### **2. Complexity-based Step Variations**\n- **Simple reasoning tasks** (e.g., basic chart interpretation):\n  - Typically involve **6 to 7 steps** (average: **6.8 steps**).\n- **Complex mathematical/logical reasoning tasks** (e.g., geometry-based problems):\n  - Require **7 to 10 steps** (average: **8.9 steps**).\n\n### **3. Implications for Model Training**\n- **Adaptive Reasoning:**  \n  - The dataset helps train models that can dynamically **adjust reasoning depth based on task complexity**.\n  - Models learn to **\"think less and faster\"** for simple tasks while **\"thinking more and slower\"** for complex ones.\n\n---\n\n## **How does Mulberry-260K impact model performance compared to standard supervised fine-tuning?**\n\nMulberry-260K significantly **enhances model reasoning and reflection** beyond what standard Supervised Fine-Tuning (SFT) achieves. Key findings from experimental evaluations:\n\n### **1. Improved Performance on Benchmarks**\n- Mulberry-trained models outperform standard models across **8 challenging benchmarks** in:\n  - **General multimodal reasoning**\n  - **Mathematical reasoning (MathVista)**\n  - **Hallucination detection (HallBench)**\n  - **Multidisciplinary reasoning (MMMU)**\n\n- Example Performance Gains (Avg. across benchmarks):\n  - **Mulberry-7B vs. Qwen2-VL-7B:** **+4.2%**\n  - **Mulberry-11B vs. LLaMA-3.2-11B-Vision:** **+7.5%**\n  - **Mulberry-8B vs. LLaVA-NeXT-8B:** **+11.0%**\n\n### **2. Comparison with Other Tree Search Methods**\n- Mulberry\u2019s CoMCTS outperforms traditional **MCTS**, **Iter-MCTS**, and **Omega-MCTS** in **search success rate (SSR)**:\n  - **GPT-4o Direct Prediction:** 58.2%\n  - **MCTS:** 63.8%\n  - **Omega-MCTS:** 66.2%\n  - **CoMCTS (Mulberry):** **80.2%** (highest)\n- **Efficiency Gain:**  \n  - **CoMCTS requires fewer search iterations** (12.7 on average) compared to traditional MCTS (42.1 iterations).\n\n### **3. Qualitative Improvements**\n- **More structured, well-defined reasoning paths** compared to traditional **chain-of-thought prompting**.\n- **Better reflection and error correction** capabilities due to the **reflective reasoning component**.\n\n### **4. Impact of Collective Learning**\n- **Ablation Study on CoMCTS:**  \n  - Adding multiple models to the **tree search process** **improves search success rates**.\n  - Example: **Adding Qwen2-VL-7B to CoMCTS alone boosts SSR by +2.4%**.\n\n### **5. Impact of Reflective Reasoning**\n- **Adding reflective reasoning data improves mathematical reasoning performance** (MathVista benchmark: **+0.8%**).\n\n---\n\n## **Conclusion**\nMulberry-260K is a **groundbreaking dataset** that:\n- **Constructs explicit, well-defined reasoning paths** using **Collective MCTS**.\n- **Incorporates multimodal sources** for a diverse and **robust reasoning dataset**.\n- **Trains models to reason step-by-step and reflect on mistakes**, improving performance over **standard fine-tuning**.\n- **Outperforms existing methods and tree search strategies**, demonstrating the **effectiveness of collective knowledge learning**.\n\nThese findings suggest that **structured, collective reasoning datasets** like Mulberry-260K **enable MLLMs to achieve superior reasoning performance** compared to traditional SFT-based training approaches.\n"
    },
    {
        "queston_id": "2412.18319v2_rqe_2",
        "answer": "## Key Limitations of Traditional MCTS for MLLMs\n\nTraditional Monte Carlo Tree Search (MCTS) methods face significant challenges when applied to Multimodal Large Language Models (MLLMs):\n\n1. **Search Effectiveness**:\n   - Traditional MCTS methods rely on self-bootstrapping, which often results in being trapped in **homogeneous low-quality nodes**.\n   - Since current MLLMs lack explicitly well-defined intermediate reasoning steps, MCTS struggles to generate diverse and high-quality search paths.\n\n2. **Search Efficiency**:\n   - Standard MCTS expands and explores **only one subsequent reasoning node per iteration**, making it inefficient for computationally expensive MLLMs.\n   - This slow progression leads to an excessive number of iterations before reaching effective reasoning paths.\n\n## How CoMCTS Leverages Collective Learning for Improved Reasoning\n\nCoMCTS (Collective Monte Carlo Tree Search) enhances traditional MCTS by introducing **collective learning**, where multiple models collaborate to **conjecture, search, and refine** reasoning paths. The key improvements include:\n\n1. **Joint Expansion Mechanism**:\n   - CoMCTS **expands diverse and complementary candidate reasoning nodes** across multiple MLLMs rather than relying on a single model.\n   - This prevents the search from being trapped in a limited reasoning space and allows the system to leverage **the strengths of multiple MLLMs**.\n\n2. **Error Positioning and Pruning**:\n   - Unlike traditional MCTS, CoMCTS **uses collective knowledge to detect and remove incorrect reasoning paths early**.\n   - Other models evaluate nodes, making error identification more robust than self-assessment.\n\n3. **Efficient Search Iterations**:\n   - CoMCTS **skips multiple intermediate steps** by selecting the last correct step as the next start node.\n   - This dramatically reduces the number of search iterations while maintaining reasoning effectiveness.\n\n4. **Reflective Reasoning Path Construction**:\n   - CoMCTS identifies both **positive and negative reasoning nodes** to generate **reflective reasoning paths**.\n   - These paths train MLLMs to dynamically correct their errors by transitioning from an incorrect node to a correct one.\n\n## Steps Introduced by CoMCTS for Better Search Performance\n\nCoMCTS operates in an **iterative tree search framework**, consisting of four key steps:\n\n### 1. **Expansion**:\n   - The current leaf node is expanded by **multiple MLLMs**, generating a diverse set of candidate reasoning nodes.\n   - This allows for **parallel search exploration** across different models, improving the diversity of reasoning paths.\n\n### 2. **Simulation and Error Positioning**:\n   - Each new candidate reasoning node is **evaluated collectively** by multiple MLLMs.\n   - Nodes with low evaluation scores are **pruned**, preventing incorrect reasoning paths from propagating.\n\n### 3. **Backpropagation**:\n   - The reasoning tree is updated **bottom-up**, adjusting node scores and visit counts.\n   - This helps in **prioritizing high-quality reasoning paths** over time.\n\n### 4. **Selection**:\n   - The next starting node is selected based on an **Upper Confidence Bound (UCB) value**, balancing exploration and exploitation.\n   - The highest UCB node becomes the new start node for the next iteration.\n\nThese steps **repeat iteratively** until an effective reasoning path is found, ensuring **both efficiency and accuracy**.\n\n## Handling Error Positioning and Reflection in Reasoning Paths\n\nCoMCTS improves reasoning robustness by explicitly handling **error positioning and reflection**:\n\n1. **Error Positioning**:\n   - During the **simulation step**, CoMCTS **identifies and filters out erroneous nodes**.\n   - This is done **collaboratively** by multiple MLLMs, ensuring more reliable error detection than self-assessment.\n\n2. **Reflective Reasoning Path Construction**:\n   - CoMCTS introduces **negative sibling nodes** into the reasoning process.\n   - A transition is created from an incorrect node to a correct one using **reflection prompts** (e.g., \u201cLet\u2019s rethink this step\u201d).\n   - This allows MLLMs to learn **dynamic correction** and improve their long-chain reasoning capabilities.\n\n## Empirical Evidence Supporting CoMCTS\u2019s Effectiveness\n\nExtensive experiments on multiple benchmarks validate the superiority of CoMCTS:\n\n### **Search Effectiveness and Efficiency (Table 4 in Paper)**\n| Method        | Search Success Rate (%) | Avg. Search Iterations |\n|--------------|------------------------|------------------------|\n| GPT-4o (direct) | 58.2 | - |\n| MCTS | 63.8 | 42.1 |\n| Omega-MCTS | 65.6 | 36.3 |\n| Iter-MCTS | 66.2 | 24.3 |\n| **CoMCTS** | **80.2** | **12.7** |\n\n- **CoMCTS achieves the highest search success rate (80.2%)** while **requiring the least number of search iterations (12.7)**.\n- Compared to traditional MCTS, **CoMCTS improves efficiency by more than 3x**.\n\n### **Performance on Various Benchmarks (Table 1 in Paper)**\n\n| Model | MathVista | MMMU | ChartQA | MM-Math | AVG Improvement |\n|-------|----------|------|---------|---------|----------------|\n| **Mulberry-7B** (trained with CoMCTS) | 63.1 (+4.2) | 61.3 | 55.0 | 83.9 | **+4.2%** |\n| **Mulberry-11B** (trained with CoMCTS) | 61.1 (+7.5) | 58.5 | 45.6 | 83.5 | **+7.5%** |\n| **Mulberry-2B** | 51.7 (+5.4) | 51.3 | 42.0 | 77.7 | **+5.4%** |\n\n- Models trained on **CoMCTS-searched data (Mulberry-260k)** outperform their baselines significantly.\n- **Mulberry-11B outperforms LLaMA-3.2-11B-Vision by +7.5%**, demonstrating **strong generalization and reasoning improvements**.\n\n### **Ablation Studies (Table 2 and Table 3 in Paper)**\n- Removing reflection data results in **performance drop (~0.8%)**, confirming the importance of reflective reasoning paths.\n- CoMCTS's collective learning approach consistently improves performance as more models contribute.\n\n## Conclusion\n\nCoMCTS introduces **collective learning** into MCTS, significantly enhancing reasoning effectiveness and efficiency for MLLMs. By leveraging multiple MLLMs, CoMCTS:\n- **Prevents getting stuck in low-quality nodes** through diverse expansion.\n- **Prunes errors early** using collective evaluation.\n- **Reduces search iterations** while improving accuracy.\n- **Enhances reflection-based correction**, making MLLMs more robust.\n\nEmpirical evidence from various benchmarks validates **CoMCTS\u2019s superiority over traditional MCTS** and other reasoning-based techniques, making it a powerful tool for multimodal reasoning.\n"
    },
    {
        "queston_id": "2412.18319v2_rqe_3",
        "answer": "# Reflective Reasoning and CoMCTS in Mulberry Models\n\n## 1. Concept of Reflective Reasoning and Its Difference from Standard Reasoning\n\nReflective reasoning is an advanced form of step-by-step reasoning where models not only generate reasoning paths but also incorporate reflection on incorrect or suboptimal steps to dynamically recalibrate their reasoning process. Unlike standard reasoning approaches, which typically follow a single trajectory from question to answer, reflective reasoning introduces explicit transitions from incorrect to correct reasoning steps, enabling a model to learn from its errors.\n\n### Differences from Standard Reasoning Approaches:\n- **Error Correction**: Reflective reasoning explicitly identifies and corrects errors, whereas standard approaches may only generate reasoning sequences without explicit verification.\n- **Dynamic Calibration**: It allows for real-time adjustments to reasoning paths based on self-identified mistakes.\n- **Integration of Negative Knowledge**: Reflective reasoning incorporates incorrect paths to guide models toward better reasoning trajectories.\n\n---\n\n## 2. CoMCTS and the Identification/Integration of Negative Sibling Nodes\n\n### **What is CoMCTS?**\nCollective Monte Carlo Tree Search (CoMCTS) is a novel method introduced in Mulberry models to enhance multimodal large language models (MLLMs) with structured, collective reasoning. It improves search effectiveness and efficiency by leveraging multiple models to explore diverse reasoning paths.\n\n### **How CoMCTS Identifies Negative Sibling Nodes?**\nCoMCTS constructs a tree of reasoning nodes, which includes both correct (positive) and incorrect (negative) paths. To enable reflective reasoning, CoMCTS identifies **negative sibling nodes** using an Upper Confidence Bound (UCB) score:\n\n1. **Sibling Node Identification**: Given a correct reasoning node \\( s \\), its **negative sibling** \\( s_{neg} \\) is selected as:\n   \\[\n   s_{neg} = \u0007rg\\min_{s' \\in Sibling(s)} (UCB(s') - UCB(s))\n   \\]\n   where \\( Sibling(s) \\) denotes nodes sharing the same parent.\n\n2. **Negative Path Integration**: The identified negative node is then integrated into the reasoning trajectory:\n   \\[\n   Y_{reflect} = Replace(Y, s, (s_{neg}, prompt_{reflect}, s))\n   \\]\n   where \\( prompt_{reflect} \\) is a predefined reflection prompt (e.g., \"Let's rethink this step as it seems incorrect\").\n\n### **How This Enhances Reflective Reasoning?**\n- Enables models to correct errors dynamically during long-chain reasoning.\n- Encourages deeper understanding by forcing models to recognize and rectify faults.\n- Reduces susceptibility to incorrect intermediate reasoning steps.\n\n---\n\n## 3. Impact of Reflective Reasoning Paths on Model Calibration and Accuracy\n\nReflective reasoning paths have a significant impact on both **model calibration** and **accuracy**:\n\n### **Impact on Model Calibration**\n- **Improves Consistency**: Models trained with reflective paths become better at avoiding inconsistencies in their reasoning process.\n- **Enhances Self-Correction**: By learning explicit transitions from incorrect to correct reasoning, the model can calibrate itself dynamically.\n- **Reduces Overconfidence**: Reflective reasoning discourages models from making overly confident but incorrect predictions.\n\n### **Impact on Accuracy**\n- **Higher Benchmark Performance**: Mulberry models trained with CoMCTS-searched reflective reasoning data achieve higher accuracy compared to baselines.\n- **Lower Error Propagation**: Models become more resilient to compounding errors in multi-step reasoning tasks.\n- **Better Long-Chain Performance**: Since errors are identified and corrected, the model maintains logical consistency across longer reasoning chains.\n\n---\n\n## 4. Reflective Reasoning\u2019s Contribution to Long-Chain Reasoning Tasks\n\nReflective reasoning plays a crucial role in **long-chain reasoning tasks** by:\n- **Preventing Error Accumulation**: Since errors are corrected at intermediate steps, later steps are less likely to be affected by initial mistakes.\n- **Guiding Complex Multi-Step Solutions**: Long mathematical and logical tasks benefit from built-in reflection mechanisms that help maintain solution validity.\n- **Mimicking Human-like Thought Processes**: Just as humans rethink and adjust their reasoning, reflective models can refine their logic iteratively.\n\n---\n\n## 5. Experimental Results Demonstrating Effectiveness in Mulberry Models\n\n### **Search Effectiveness of CoMCTS**\nTable results show that CoMCTS significantly improves **Search Success Rate (SSR)** while reducing search iterations:\n\n| Method        | Search Success Rate (%) | Avg. Search Iteration |\n|--------------|-------------------------|------------------------|\n| GPT-4o (Direct) | 58.2 | - |\n| MCTS | 63.8 | 42.1 |\n| Omega-MCTS | 66.2 | 24.3 |\n| CoMCTS | **80.2** | **12.7** |\n\n### **Performance Improvement of Mulberry Models**\nExperiments across multiple benchmarks confirm that Mulberry models trained on CoMCTS-searched reasoning data outperform both **open-source and closed-source** models:\n\n| Model | MathVista (%) | MMStar (%) | MMMU (%) | ChartQA (%) | AVG (%) |\n|-------|-------------|------------|-----------|------------|---------|\n| Qwen2-VL-7B (Baseline) | 58.2 | 60.7 | 54.1 | 83.0 | 54.7 |\n| **Mulberry-7B** | **63.1** | **61.3** | **55.0** | **83.9** | **58.9** (+4.2) |\n\n### **Ablation Study on Reflective Reasoning**\nAn ablation study confirms that **including reflective reasoning paths further enhances accuracy**:\n\n| Model | Without Reflection (%) | With Reflection (%) | Improvement (%) |\n|--------|-------------------------|---------------------|-----------------|\n| Mulberry-7B | 50.9 | **51.7** | +0.8 |\n\n---\n\n## 6. Conclusion\n\nThe integration of **reflective reasoning** into CoMCTS and Mulberry models has resulted in:\n1. **Improved reasoning accuracy** by enabling error correction and step-wise reflection.\n2. **Enhanced model calibration** through dynamic reasoning path adjustments.\n3. **Superior long-chain reasoning** by mitigating error accumulation in complex problems.\n4. **Significant empirical gains**, with Mulberry outperforming major state-of-the-art multimodal models.\n\nMulberry\u2019s success demonstrates that **learning to reason reflectively**\u2014instead of relying solely on forward generation\u2014yields more **accurate, robust, and explainable** AI models.\n"
    }
]